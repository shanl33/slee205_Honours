---
title: "Code-based open-source software for teaching interactive data visualisation"
author: "Shan-I Lee"
runtime: shiny
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
# For tidying of NCEA data
library(tidyr) 
library(dplyr)
# For reading xls binary file for 2016 schools data
library(gdata)
# For plots
library(GGally)
# For interactivity
library(plotly)
library(shiny)
library(crosstalk)
# For crabs data
library(MASS)
# For tours
library(tourr)
```

## Introduction

This report will discuss the developments since last semester on using code-based open-source software for teaching interactive data visualisation. The insights gained from developing an exemplar of interactive techniques applied to data analysis, will form the basis of discussion. Implications for teaching, such as the choice of techniques, software and datasets will then be discussed.

### Development of a comprehensive exemplar 

A narrative on how ideas for the exemplar emerged and changed over its development will be outlined and examined with respect to the insights gained in the process.

#### The NCEA dataset

The motivation to develop an interactive exemplar for cluster analysis emerged from reading literature on the topic, as well as finding "real" data for which it was of interest to see if there was any such underlying structure. Data on the performance of New Zealand schools in the National Certificate of Educational Achievement (NCEA), at the four qualification levels, Level One, Two, Three (L1, L2, L3) and University Entrance (UE), were obtained from the New Zealand Qualifications Authority (NZQA) website. Information on the school decile, region and a "small" cohort warning, were also provided in the data. The decile rating is a measure of the general income level of the families of students attending the school. The socio-economic background of students increases as the decile increase from one to ten. A handful of schools have a decile rating of zero, due to unique circumstances that make them exempt from the socio-economic measure. The achievement rate of a school for each qualification level was quantified in a few ways. The achievement indicator chosen for this analysis was the proportion of students at the school who were successful in obtaining the qualification level, given that they were entered in enough standards to have the opportunity to earn the qualification in the 2016 school year. This is referred to as the "Current Year Achievement Rate" for the "Participating Cohort" by the NZQA (see <http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/NZQA-Secondary-Statistics-Consolidated-Data-Files-Short-Guide.pdf>). 

Only schools with achievement indicators across all four qualification levels were retained, thus reducing the dataset to 408 schools from around New Zealand. The focus of analysis will be on its subset of 91 Auckland schools, but the New Zealand dataset of 408 schools will be used to demonstrate how interactive techniques can be useful as the number of observations increases.

The focus of analysis will be on the Auckland subset because it is less affected by the unreliability of small sample sizes. The NZQA indicator of a "small" cohort was at a very low threshold of fewer than five candidates for any qualification level. Being the most populated city in New Zealand, Auckland has many of the larger schools, but there may still be some schools left in the analysis that have less than 30 candidates entered in a qualification level. The first few observations from the data set of 91 schools in the Auckland region are shown below.

```{r}
nzqa2016 <- read.csv("http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/2016/Qualification-Statistics-School-2016-29032017.csv")
# Drop vars that will not be used (eg. cumulative achievement)
nzqa2016 <- nzqa2016[,-c(1,8,10)]
names(nzqa2016) <- c("Decile", "Region", "School", "Year", "Qualification", "Achieve_participate", "Achieve_roll", "Small_sch")
levels(nzqa2016$Qualification) <- c("L1", "L2", "L3", "UE")
# Subset to use only Year 11 with Level 1, etc
nzqa <- nzqa2016 %>% filter(((Qualification=="L1") & (Year==11)) | 
                          ((Year==12) & (Qualification=="L2")) |
                          ((Year==13) & (Qualification=="L3")) | 
                          ((Year==13) & (Qualification=="UE"))) %>%
  # Reshape so that each row represents an observation (a school)
  # Current.Achievement.Rate.Participation kept for analysis only
  spread(Qualification, Achieve_participate, fill=0) %>%
  group_by(School) %>%
  summarise_at(c("L1", "L2", "L3", "UE"), sum) %>%
  inner_join(nzqa2016[, c(1, 2, 3, 8)]) %>% # Add Decile and Region and Small_sch variables
  distinct() %>% 
  filter(!((L1==0)&(L2==0)&(L3==0))) #Remove schools with 0% achievement rate for all levels

# Function to replace 0% with NA
zeros <- function(col) {
  replace(col, col==0, NA)
}

nzqa[2:5] <- sapply(nzqa[2:5], zeros)
# Remove schools with 'small cohort' warning (obscures pattern in non-small cohorts).
nzqa <- nzqa[nzqa$Small_sch=="",] # 439 school left
nzqa <- nzqa[, -8] # Remove Small_sch var
# Remove schools with any NA values 
nzqa <- nzqa[complete.cases(nzqa),] # 408 NZ schools
# Subset Auckland schools only
akl <- as.data.frame(nzqa[nzqa$Region=="Auckland", -7]) # 91 AKL schools
rownames(akl) <- akl$School # Need for tooltips in tour
head(akl[-1], n=3)
```

#### Static visual analysis

A question that naturally arises from the NCEA data is whether a school's performance is related to its decile rating. 

The pairs plot in Figure 1 shows the achievement rates at L1, L2 and L3 have a weak relationship with decile rating, but the positive correlation is strong at UE. There appears to be an increasing "lower bound" to achievement rates for L1, L2 and L3, as decile increases, but there is a lot of scatter above this boundary. In the bivariate scatterplots we can also see the spread of achievement rates varying across decile groups. The variation in achievement rates decreases as the decile increases (from one), across the L1, L2 and L3 qualification levels. We can see many schools approaching the maximum 100% achievement rate, for L1, L2 and L3, hence it is not surprising to see their univariate distributions are skewed to the left in Figure 2. The distribution of achievement rates for UE is less skewed and hints at two possible groupings. Furthermore performance across the qualification levels appear to be positively correlated, especially between L1 and L2. Hence the low-dimensional plots indicate non-normality, unequal spread between groups and multicollinearity.

##### Figure 1: Pairs plot for NCEA data on Auckland schools
```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(akl[-1], lower.panel=panel.cor)
```

##### Figure 2: Univariate distributions for NCEA data on Auckland schools

```{r}
NCEA_hist <- function(x, title) {hist(x, xlab="Achievement rate", main=title)}
layout(matrix(1:4, byrow=1, ncol=2))
NCEA.hists <- mapply(NCEA_hist, akl[2:5], colnames(akl[2:5]))
```

#### Multivariate visual representations

The pairs plot in Figure 2 provided a glimpse into the multivariate distribution of achievement rates across the four qualification levels. The parallel coordinates plot (PCP) shown below in Figure 3 allows us to further compare the multivariate distributions of achievement rates for different decile groups, as well as identify high dimensional clustering and outliers.

The ordering of axes in a PCP greatly affects the quality of the graphical analysis, hence interactivity that enables reordering of axes is recommended (Unwin, 2015). In the case of the NCEA data, the natural ordering of the four qualification levels by difficulty, conincides with the recommendation from Cook and Swayne (2007) to order the axes based on correlation. In addition, Unwin (2015) highlights the layering of colours also needs to be considered carefully, since the last group assigned a colour will dominate the other lines.

The positive relationships previously identified in the pairs plot, should translate to parallel lines between axes in the PCP, as opposed to a "criss-cross" pattern for negative correlation. The static plot in Figure 3 questions whether the positive relationships hold true for schools with low achievement rates and in some decile groups. The higher decile schools in Auckland appear to dominate the high achievement rates across all qualification levels, while lower decile schools are inconsistent with each other in terms of their performance across the levels. Although there are only 91 observations (lines), it is quite difficult to identify even "ball park boundaries", on the 11-point decile scale, to distinguish between "higher" and "lower" decile schools when describing possible patterns.

##### Figure 3: Parallel coordinates plot for NCEA data on Auckland schools
```{r}
# Plot with consistent labels
ggpcp <- function(x, a=1) {
  ggparcoord(data=x, columns=2:5, scale="uniminmax", 
             mapping=aes(colour=as.factor(Decile), label=School, label1=Decile), alphaLines=a) +
  labs(x="Qualification level", y="Achievement rate", colour="Decile")
}

ggpcp(akl) + ggtitle("Achievement of Auckland schools in 2016")
```

The following two plots demonstrate how alpha blending can help minimise the effects of overplotting as the number of observations increase. It is easier to check whether the patterns identified in Auckland schools extend to the 408 schools across New Zealand, using Figure 5 where alpha blending is applied, rather than Figure 4. The performance of high achieving lower decile schools is less "drowned out" by the dominance of their higher decile counterparts, when alpha blending is used.  

##### Figure 4: Parallel coordinates plot without alpha blending
```{r, echo=FALSE}
ggpcp(nzqa) + ggtitle("Achievement of NZ schools in 2016")
```

##### Figure 5: Parallel coordinates plot with alpha blending
```{r}
nz.pcp <- ggpcp(nzqa, a=0.5) + ggtitle("Achievement of NZ schools in 2016")
nz.pcp
```

#### Leveraging static plots with interactivity

The use of colour and interactive techniques are recommended for maximising the effectiveness of a PCP. Venables and Ripley (2002) argue parallel coordinate plots are "often too 'busy' without means of interaction" (p. 315). Figure 6 demonstrates how adding interactive filtering helps to further reduce the problems with overplotting and allows direct comparison between selected decile groups.

One of the strengths of a PCP is in identifying multivariate features, such as outliers (Cook & Swayne, 2007). Figure 3 suggests a school's performance can be unusual in two ways, either it performs inconsistently to the bivariate correlations between the qualification levels (this was previously noted as typical of "lower" decile schools), or its achievement rates across the levels are unusual compared to the rest of its decile group. The latter becomes difficult to see for the New Zealand dataset, in the static plots (Figures 4 and 5), even with alpha blending applied. The filtering feature of Figure 6 overcomes the problems caused by overplotting by allowing the user to isolate the distribution of each decile group (via a double-click on the legend). Furthermore the interactive tooltip feature enables the possible outliers to be identified by school name, or observation number, as shown in Figure 6. 

**Difficult to "follow" individual observations (lines) across the variables without being able to brush** 
* Demonstrate w decile 1 or 10 schools only and trying to follow unusual schools.
* Brushing of pcp was used in the draft papers by Sievert (`plotly+crosstalk`?) and in this paper with `animint`.

##### Figure 6: Parallel coordinates plot with interactivity

See Sievert's pcps where brushing is possible and individual identification (with correct label name):
* Interactive: <https://pedestrians.cpsievert.me/missing-by-time/>
* Code: <https://github.com/cpsievert/pedestrians/blob/master/docs/missing-by-time.R>

```{r}
ggplotly(nz.pcp, tooltip=c("label1", "x", "y", "label"))
```

The PCP in Figure 3 suggests that patterns of performance across decile groups, if they exist, are difficult to distinguish at the multivariate level for Auckland schools. Principal component analysis (PCA) provides a way to reveal interesting multivariate structure, through finding projections of the data that show maximal variability (Venables & Ripley, 2002). 

A plot of the first two principal components of the Auckland schools dataset is shown in Figure 7. The decile of the schools is represented by the colour and plotting symbol. The axes for the original variables, reflecting the loadings of the principal components, indicate that the first principal component considers the schools' performance across all four qualification levels, while the second principal component contrasts performance in UE against the remaining qualifications. Not surprisingly the plot shows more spread across the first principal component since it explains a much greater proportion of the variation in the data. The first principal component reveals a division between the majority of schools and a smaller group, that is positioned away from the variable axes shown. We can see the smaller group of schools are decile five and below, except for one decile nine school. There is also a decile ten school that appears to be unusual when examining both principal components. The use of colour highlights the remaining decile nine and ten schools as similar in performance, as weighted by the principal components. On the other hand schools from the other deciles seem to be more spread out from each other.

##### Figure 7: First two principal components for Auckland schools
```{r}
# Static PCA plot
# Function for PCA and plot
# scale.factor is an arbitary value that scales the loadings axes so that they can be on a comparable scale as the standardised PCs (scores). 
# nudge argument also depends on the range of PC1 (used for enhancing the legibility of text labels on loadings axes).
ncea_PCA <- function(df, scale.factor=20, nudge=-0.2, decile.pch=T, gp="Decile") {
  # Perform PCA
  pca <- prcomp(df[2:5], scale.=T)
  # Explained variance
  exp.var <- round(pca$sdev^2/sum(pca$sdev^2)*100, 1)
  # Scores (rotated principal components)
  scores <- data.frame(t(t(pca$x[, 1:2])*(pca$sdev[1:2]^-1)), df[-(2:5)], Group=df[, gp])
  scores$Decile <- as.factor(df$Decile)
  #scores$Group <- df$gp
  #scores$Group <- df[, gp]
  axis.limit <- c(-round(max(abs(scores[1:2])), 1), round(max(abs(scores[1:2])), 1))
  # Set up for linked brushing for Fig 8
  sdPCA <- SharedData$new(scores, key=~School, group="nceaPCA")
  # Variable axes (loadings)
  lambda <- pca$sdev[1:2]/sqrt(nrow(df)-1)
  loadings <- data.frame(varnames = rownames(pca$rotation),
                              t(t(pca$rotation[, 1:2])*lambda*scale.factor))
  # Plot of first two PCs
  p <- ggplot(loadings) + 
    geom_segment(aes(x=0, y=0, xend=PC1, yend=PC2), colour="grey35") +
    geom_text(aes(x=PC1, y=PC2, label=varnames), colour="grey35", nudge_x=nudge) +
    labs(x=paste("PC1 (", exp.var[1], "% explained var.)", sep=""),
         y=paste("PC2 (", exp.var[2], "% explained var.)", sep="")) +
    scale_x_continuous(limits=axis.limit) +
    scale_y_continuous(limits=axis.limit*1.1) +
    theme(
      panel.border = element_rect(colour="grey", fill=NA),
      panel.background = element_blank(),
      legend.position = "none")
  if (decile.pch) {
    plot <- p + geom_text(data=sdPCA, aes(x=PC1, y=PC2, label=Decile, colour=Decile, label1=School))
  } else {
    plot <- p + geom_point(data=sdPCA, aes(x=PC1, y=PC2, colour=Group, label1=School))
  }
  return(plot)
}
# Static plot
ncea_PCA(akl) + ggtitle("Achievement of Auckland schools in 2016")
```

The principal components plot in Figure 7 provided a view of the multivariate distribution of the Auckland schools dataset that was less easily affected by overplotting than a static PCP. Hence refinements on observations were possible. From the parallel coordinate plots we observed that "higher" decile schools performed more consistently with each other and dominated across the four qualification levels, but it was difficult to quantify the decile "cut off" for such schools. The PCA suggests these are the decile nine and ten Auckland schools, with the exception of two schools. One cannot help but wonder: Who are the two unusual decile nine and ten Auckland schools? The interactive tooltips in Figure 8 instantly satifies this curiosity and hence demonstrates the usefulness of being able to directly identify unusual observations. The linked brushing between visual representations of the PCA model and the original variables, also enable confirmation of previous observations and a better understanding of the PCA model.
* closer to variable axes means what? Anything? Better performance at that level?
* link to decile plot as well as pcp or pairs plot of performance across the 4 qualifications.

```{r}
# Function for linked factor plot
ncea_factor <- function(df, gp="Decile") {
  # Set up for linked brushing 
  sdGroup <- SharedData$new(
    data.frame(School=df$School, Group=df[, gp]), 
    key=~School, group="nceaPCA") 
  # Static plot
  factor.p <- ggplot(sdGroup) +
    geom_jitter(aes(y=Group, x=1, colour=Group, label=School), width=0.1, height=0) +
    labs(x=as.character(gp), y="") +
    scale_x_continuous(limits=c(0.7, 1.3)) +
    theme(
      panel.border=element_rect(colour="grey", fill=NA),
      panel.background=element_blank(),
      legend.position="none",
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())
  # Interactive linked plot
  link.factor <- ggplotly(factor.p, tooltip=c("colour", "label")) %>%
    layout(dragmode="select", yaxis=list(side="right"), margin=list(r=30)) %>%
    highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T)
  return(link.factor)
}
```

##### Figure 8: First two principal components for Auckland schools with interactivity
```{r}
# Linked brushing of PCA and decile plot
akl$Decile <- as.factor(akl$Decile)
akl.PCA <- ncea_PCA(akl, decile.pch=F) + 
  theme(axis.text=element_blank(),
        axis.ticks=element_blank()) +
  ggtitle("Achievement of Auckland schools in 2016")

# Link decile plot
link.PC <- ggplotly(akl.PCA, tooltip=c("label1")) %>%
  layout(dragmode="select") %>%
  highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T)

# Link decile plot
link.decile <- ncea_factor(akl)

subplot(link.PC, link.decile, widths=c(0.7, 0.3), margin=0, titleX=T, titleY=T)
```

```{r}
sdAkl <- SharedData$new(akl[2:5], group="nceaPCA")
Akl.pairs <- ggpairs(sdAkl)
ggplotly(Akl.pairs) %>%
  layout(dragmode="select") %>%
        highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T, dynamic=T)
```

#### NZ schools
Data on school size by year group and ethnicity for 2016, was obtained from the government website, Education Counts (2017). 
```{r, eval=FALSE}
# Download file on school demographics (includes counts by Year group)
download.file("https://www.educationcounts.govt.nz/__data/assets/excel_doc/0005/152609/Student-rolls-by-School-2010-2016.xlsx", "schools.xlsx")
# Takes a long time to extract 2016 data
schools2016 <- read.xls("schools.xlsx", sheet="2016", skip=2, header=T)
# Subset relevant variables
schools2016 <- schools2016[c(2, 4, 10, 13:18, 34:36)]
# Tidy up variable names
colnames(schools2016)[9] <- "EuropeanPakeha"
colnames(schools2016)[4] <- "Maori"
# Keep only schools with secondary level students
schools2016 <- schools2016 %>%
  filter(!((Type=="Full Primary")|(Type=="Intermediate")))
head(schools2016)

# Merge with NZQA data 
# School ID number not available on NZQA data and some names have changed
# (eg. Auckland Grammar)
levels(schools2016$School.Name) <- c(levels(schools2016$School.Name), "Auckland Grammar School")
schools2016[schools2016$School.Name=="Auckland Grammar", 1] <- "Auckland Grammar School"
nzqa.sch <- merge(nzqa, schools2016, by.x="School", by.y="School.Name") # 348 schools left
# Change ethinicity counts to proportions
# MELAA refers to Middle Eastern/Latin American/African
nzqa.sch[10:15] <- sapply(nzqa.sch[10:15], function(x) {round(x/nzqa.sch$Total, 2)})
nzqa.sch$Other <- 1 - Reduce("+", nzqa.sch[c(10:13, 15)]) 
# Minimum cohort size for Yr 11 to 13
nzqa.sch$Min.Cohort <- sapply(1:nrow(nzqa.sch), function(x) {min(nzqa.sch[x, 16:18])})
nzqa.sch <- droplevels(nzqa.sch)
save(nzqa.sch, file="nzqa.sch.RData")
```
The minimum cohort size for Year 11, 12 and 13 can be used as indicator of whether the achievement rates are based on small sample sizes. We can see the minimum cohort sizes for 
```{r}
# Load merge school data
load("nzqa.sch.RData")
nzqa.sch$Decile <- as.factor(nzqa.sch$Decile)
summary(nzqa.sch$Min.Cohort)
summary(nzqa.sch[16:19])
```

As expected we see less spread in the PCA plot as the minimum cohort size is increased and the first principal component is able to explain more the variation in the data. 
Once the minimum cohort size is above 20 the amount of variability continues to decrease but at a slower rate.
The biggest drop in unexplained variability occurs when the minimum cohort size is increased from 10 to 20.

The position of the axes remain reasonably consistent with the first principal component being a measure of overall performance and the second component contrasting L1 and L2 preformance against L3 and UE. 

The decile patterns previously noted for Auckland schools, where decile nine and ten schools are more consistent with each other in performance than other deciles, appear to hold for New Zealand schools in general as we vary the minimum cohort size considered. 

When the minimum cohort size is set at 100, the PCA plot appears quite similar to the plot for Auckland schools but with fewer schools from decile one. We can verify this quickly by  interactive drop-down menu that allows us to choose the variable "Region" and brush the group of Auckland schools allows to verify this 
```{r}
inputPanel(
  selectInput("group", "Select variable", choices=as.list(colnames(nzqa.sch)[6:15]), selected="Decile"),
  div(style="width: 600px;", sliderInput("cohort", label="Minimum of Year 11, 12, 13 cohorts", min=0, max=100, step=10, value=0, animate=T))
)

output$pca <- renderPlotly({
  static.pca <- subset(nzqa.sch, Min.Cohort>=input$cohort) %>% 
    ncea_PCA(scale.factor=50, decile.pch=F, gp=input$group) + 
    ggtitle("Achievement of NZ schools in 2016")
  ggplotly(static.pca, tooltip=c("label1")) %>%
  layout(dragmode="select") %>%
  highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T)
})

output$gp_plot <- renderPlotly({
  subset(nzqa.sch, Min.Cohort>=input$cohort) %>%
    ncea_factor(gp=input$group)
})

renderUI({
  splitLayout(
    plotlyOutput("pca", height=550, width=550),
    plotlyOutput("gp_plot", height=550, width=80)
    )
})
```
