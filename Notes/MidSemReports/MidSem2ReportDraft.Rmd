---
title: "Code-based open-source software for teaching interactive data visualisation"
author: "Shan-I Lee"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
# For tidying of NCEA data
library(tidyr) 
library(dplyr)
library(GGally)
library(plotly)
library(MASS)
library(tourr)
library(shiny)
library(crosstalk)
#library(gridExtra)
```

## Introduction

This report will discuss the developments since last semester on using code-based open-source software for teaching interactive data visualisation. The insights gained from developing an exemplar of interactive techniques applied to data analysis, will form the basis of discussion. Implications for teaching, such as the choice of techniques, software and datasets will then be discussed.

### Development of a comprehensive exemplar 

A narrative on how ideas for the exemplar emerged and changed over its development will be outlined and examined with respect to the insights gained in the process.

#### The NCEA dataset

The motivation to develop an interactive exemplar for cluster analysis emerged from reading literature on the topic, as well as finding "real" data for which it was of interest to see if there was any such underlying structure. Data on the performance of New Zealand schools in the National Certificate of Educational Achievement (NCEA), at the four qualification levels, Level One, Two, Three (L1, L2, L3) and University Entrance (UE), were obtained from the New Zealand Qualifications Authority (NZQA) website. Information on the school decile, region and a "small" cohort warning, were also provided in the data. The decile rating is a measure of the general income level of the families of students attending the school. The socio-economic background of students increases as the decile increase from one to ten. A handful of schools have a decile rating of zero, due to unique circumstances that make them exempt from the socio-economic measure. The achievement rate of a school for each qualification level was quantified in a few ways. The achievement indicator chosen for this analysis was the proportion of students at the school who were successful in obtaining the qualification level, given that they were entered in enough standards to have the opportunity to earn the qualification in the 2016 school year. This is referred to as the "Current Year Achievement Rate" for the "Participating Cohort" by the NZQA (see <http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/NZQA-Secondary-Statistics-Consolidated-Data-Files-Short-Guide.pdf>). 

Only schools with achievement indicators across all four qualification levels were retained, thus reducing the dataset to 408 schools from around New Zealand. The focus of analysis will be on its subset of 91 Auckland schools, but the New Zealand dataset of 408 schools will be used to demonstrate how interactive techniques can be useful as the number of observations increases.

The focus of analysis will be on the Auckland subset because it is less affected by the unreliability of small sample sizes. The NZQA indicator of a "small" cohort was at a very low threshold of fewer than five candidates for any qualification level. Being the most populated city in New Zealand, Auckland has many of the larger schools, but there may still be some schools left in the analysis that have less than 30 candidates entered in a qualification level. The first few observations from the data set of 91 schools in the Auckland region are shown below.

```{r}
nzqa2016 <- read.csv("http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/2016/Qualification-Statistics-School-2016-29032017.csv")
# Drop vars that will not be used (eg. cumulative achievement)
nzqa2016 <- nzqa2016[,-c(1,8,10)]
names(nzqa2016) <- c("Decile", "Region", "School", "Year", "Qualification", "Achieve_participate", "Achieve_roll", "Small_sch")
levels(nzqa2016$Qualification) <- c("L1", "L2", "L3", "UE")
# Subset to use only Year 11 with Level 1, etc
nzqa <- nzqa2016 %>% filter(((Qualification=="L1") & (Year==11)) | 
                          ((Year==12) & (Qualification=="L2")) |
                          ((Year==13) & (Qualification=="L3")) | 
                          ((Year==13) & (Qualification=="UE"))) %>%
  # Reshape so that each row represents an observation (a school)
  # Current.Achievement.Rate.Participation kept for analysis only
  spread(Qualification, Achieve_participate, fill=0) %>%
  group_by(School) %>%
  summarise_at(c("L1", "L2", "L3", "UE"), sum) %>%
  inner_join(nzqa2016[, c(1, 2, 3, 8)]) %>% # Add Decile and Region and Small_sch variables
  distinct() %>% 
  filter(!((L1==0)&(L2==0)&(L3==0))) #Remove schools with 0% achievement rate for all levels

# Function to replace 0% with NA
zeros <- function(col) {
  replace(col, col==0, NA)
}

nzqa[2:5] <- sapply(nzqa[2:5], zeros)
# Remove schools with 'small cohort' warning (obscures pattern in non-small cohorts).
nzqa <- nzqa[nzqa$Small_sch=="",] # 439 school left
nzqa <- nzqa[, -8] # Remove Small_sch var
# Remove schools with any NA values 
nzqa <- nzqa[complete.cases(nzqa),] # 408 NZ schools
# Subset Auckland schools only
akl <- as.data.frame(nzqa[nzqa$Region=="Auckland", -7]) # 91 AKL schools
rownames(akl) <- akl$School # Need for tooltips in tour
head(akl[-1], n=3)
```

#### Static visual analysis

A question that naturally arises from the NCEA data is whether a school's performance is related to its decile rating. 

The pairs plot in Figure 1 shows the achievement rates at L1, L2 and L3 have a weak relationship with decile rating, but the positive correlation is strong at UE. There appears to be an increasing "lower bound" to achievement rates for L1, L2 and L3, as decile increases, but there is a lot of scatter above this boundary. In the bivariate scatterplots we can also see the spread of achievement rates varying across decile groups. The variation in achievement rates decreases as the decile increases (from one), across the L1, L2 and L3 qualification levels. We can see many schools approaching the maximum 100% achievement rate, for L1, L2 and L3, hence it is not surprising to see their univariate distributions are skewed to the left in Figure 2. The distribution of achievement rates for UE is less skewed and hints at two possible groupings. Furthermore performance across the qualification levels appear to be positively correlated, especially between L1 and L2. Hence the low-dimensional plots indicate non-normality, unequal spread between groups and multicollinearity.

##### Figure 1: Pairs plot for NCEA data on Auckland schools
```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(akl[-1], lower.panel=panel.cor)
```

##### Figure 2: Univariate distributions for NCEA data on Auckland schools

```{r, echo=FALSE}
NCEA_hist <- function(x, title) {hist(x, xlab="Achievement rate", main=title)}
layout(matrix(1:4, byrow=1, ncol=2))
NCEA.hists <- mapply(NCEA_hist, akl[2:5], colnames(akl[2:5]))
```

#### Multivariate visual representations

The pairs plot in Figure 2 provided a glimpse into the multivariate distribution of achievement rates across the four qualification levels. The parallel coordinates plot (PCP) shown below in Figure 3 allows us to further compare the multivariate distributions of achievement rates for different decile groups, as well as identify high dimensional clustering and outliers.

The ordering of axes in a PCP greatly affects the quality of the graphical analysis, hence interactivity that enables reordering of axes is recommended (Unwin, 2015). In the case of the NCEA data, the natural ordering of the four qualification levels by difficulty, conincides with the recommendation from Cook and Swayne (2007) to order the axes based on correlation. In addition, Unwin (2015) highlights the layering of colours also needs to be considered carefully, since the last group assigned a colour will dominate the other lines.

The positive relationships previously identified in the pairs plot, should translate to parallel lines between axes in the PCP, as opposed to a "criss-cross" pattern for negative correlation. The static plot in Figure 3 questions whether the positive relationships hold true for schools with low achievement rates and in some decile groups. The higher decile schools in Auckland appear to dominate the high achievement rates across all qualification levels, while lower decile schools are inconsistent with each other in terms of their performance across the levels. Although there are only 91 observations (lines), it is quite difficult to identify even "ball park boundaries", on the 11-point decile scale, to distinguish between "higher" and "lower" decile schools when describing possible patterns.

##### Figure 3: Parallel coordinates plot for NCEA data on Auckland schools
```{r}
# Plot with consistent labels
ggpcp <- function(x, a=1) {
  ggparcoord(data=x, columns=2:5, scale="uniminmax", 
             mapping=aes(colour=as.factor(Decile), label=School, label1=Decile), alphaLines=a) +
  labs(x="Qualification level", y="Achievement rate", colour="Decile")
}

ggpcp(akl) + ggtitle("Achievement of Auckland schools in 2016")
```

The following two plots demonstrate how alpha blending can help minimise the effects of overplotting as the number of observations increase. It is easier to check whether the patterns identified in Auckland schools extend to the 408 schools across New Zealand, using Figure 5 where alpha blending is applied, rather than Figure 4. The performance of high achieving lower decile schools is less "drowned out" by the dominance of their higher decile counterparts, when alpha blending is used.  

##### Figure 4: Parallel coordinates plot without alpha blending
```{r, echo=FALSE}
ggpcp(nzqa) + ggtitle("Achievement of NZ schools in 2016")
```

##### Figure 5: Parallel coordinates plot with alpha blending
```{r}
nz.pcp <- ggpcp(nzqa, a=0.5) + ggtitle("Achievement of NZ schools in 2016")
nz.pcp
```

#### Leveraging static plots with interactivity

The use of colour and interactive techniques are recommended for maximising the effectiveness of a PCP. Venables and Ripley (2002) argue parallel coordinate plots are "often too 'busy' without means of interaction" (p. 315). Figure 6 demonstrates how adding interactive filtering helps to further reduce the problems with overplotting and allows direct comparison between selected decile groups.

One of the strengths of a PCP is in identifying multivariate features, such as outliers (Cook & Swayne, 2007). Figure 3 suggests a school's performance can be unusual in two ways, either it performs inconsistently to the bivariate correlations between the qualification levels (this was previously noted as typical of "lower" decile schools), or its achievement rates across the levels are unusual compared to the rest of its decile group. The latter becomes difficult to see for the New Zealand dataset, in the static plots (Figures 4 and 5), even with alpha blending applied. The filtering feature of Figure 6 overcomes the problems caused by overplotting by allowing the user to isolate the distribution of each decile group (via a double-click on the legend). Furthermore the interactive tooltip feature enables the possible outliers to be identified by school name, or observation number, as shown in Figure 6. 

**Difficult to "follow" individual observations (lines) across the variables without being able to brush** 
+ Demonstrate w decile 1 or 10 schools only and trying to follow unusual schools.
+ Look for reading where brushing of pcp was used (and animint?)

##### Figure 6: Parallel coordinates plot with interactivity

```{r}
ggplotly(nz.pcp, tooltip=c("label1", "x", "y", "label"))
```

The PCP in Figure 3 suggests that patterns of performance across decile groups, if they exist, are difficult to distinguish at the multivariate level for Auckland schools. Principal component analysis (PCA) provides a way to reveal interesting multivariate structure, through finding projections of the data that show maximal variability (Venables & Ripley, 2002). 

A plot of the first two principal components of the Auckland schools dataset is shown in Figure 7. The decile of the schools is represented by the colour and plotting symbol. The axes for the original variables, reflecting the loadings of the principal components, indicate that the first principal component considers the schools' performance across all four qualification levels, while the second principal component contrasts performance in UE against the remaining qualifications. Not surprisingly the plot shows more spread across the first principal component since it explains a much greater proportion of the variation in the data. The first principal component reveals a division between the majority of schools and a smaller group, that is positioned away from the variable axes shown. We can see the smaller group of schools are decile five and below, except for one decile nine school. There is also a decile ten school that appears to be unusual when examining both principal components. The use of colour highlights the remaining decile nine and ten schools as similar in performance, as weighted by the principal components. On the other hand schools from the other deciles seem to be more spread out from each other.

##### Figure 7: First two principal components for Auckland schools
```{r}
# Static PCA plot
# Function for PCA and plot
# scale.factor is an arbitary value that scales the loadings axes so that they can be on a comparable scale as the standardised PCs (scores). 
# nudge argument also depends on the range of PC1 (used for enhancing the legibility of text labels on loadings axes).
ncea_PCA <- function(df, scale.factor=20, nudge=-0.2, decile.pch=T) {
  # Perform PCA
  pca <- prcomp(df[2:5], scale.=T)
  # Explained variance
  exp.var <- round(pca$sdev^2/sum(pca$sdev^2)*100, 1)
  # Scores (rotated principal components)
  scores <- data.frame(df[1], t(t(pca$x[, 1:2])*(pca$sdev[1:2]^-1)))
  scores$Decile <- as.factor(df$Decile)
  axis.limit <- c(-round(max(abs(scores[2:3])), 1), round(max(abs(scores[2:3])), 1))
  # Set up for linked brushing in Fig 8
  sdPCA <- SharedData$new(scores, key=~School, group="nceaPCA")
  # Variable axes (loadings)
  lambda <- pca$sdev[1:2]/sqrt(nrow(df)-1)
  loadings <- data.frame(varnames = rownames(pca$rotation), 
                              t(t(pca$rotation[, 1:2])*lambda*scale.factor))
  # Plot of first two PCs
  p <- ggplot(loadings) + 
    geom_segment(aes(x=0, y=0, xend=PC1, yend=PC2), colour="grey35") +
    geom_text(aes(x=PC1, y=PC2, label=varnames), colour="grey35", nudge_x=nudge) +
    labs(x=paste("PC1 (", exp.var[1], "% explained var.)", sep=""),
         y=paste("PC2 (", exp.var[2], "% explained var.)", sep="")) +
    scale_x_continuous(limits=axis.limit) +
    scale_y_continuous(limits=axis.limit*1.1) +
    theme(
      panel.border = element_rect(colour="grey", fill=NA),
      panel.background = element_blank(),
      legend.position = "none")
  if (decile.pch) {
    plot <- p + geom_text(data=sdPCA, aes(x=PC1, y=PC2, label=Decile, colour=Decile, label1=School))
  } else {
    plot <- p + geom_point(data=sdPCA, aes(x=PC1, y=PC2, colour=Decile, label1=School))
  }
  return(plot)
}
# Static plot
ncea_PCA(akl) + ggtitle("Achievement of Auckland schools in 2016")
```

The principal components plot in Figure 7 provided a view of the multivariate distribution of the Auckland schools dataset that was less easily affected by overplotting than a static PCP. Hence refinements on observations were possible. From the parallel coordinate plots we observed that "higher" decile schools performed more consistently with each other and dominated across the four qualification levels, but it was difficult to quantify the decile "cut off" for such schools. The PCA suggests these are the decile nine and ten Auckland schools, with the exception of two schools. One cannot help but wonder: Who are the two unusual decile nine and ten Auckland schools? The interactive tooltips in Figure 8 instantly satifies this curiosity and hence demonstrates the usefulness of being able to directly identify unusual observations. The linked brushing between visual representations of the PCA model and the original variables, also enable confirmation of previous observations and a better understanding of the PCA model.
+ closer to variable axes means what? Anything? Better performance at that level?
+ link to decile plot as well as pcp or pairs plot of performance across the 4 qualifications.

##### Figure 8: First two principal components for Auckland schools with interactivity
```{r}
# Linked brushing of PCA and decile plot
akl.PCA <- ncea_PCA(akl, decile.pch=F) + 
  theme(axis.text=element_blank(),
        axis.ticks=element_blank()) +
  ggtitle("Achievement of Auckland schools in 2016")

# Link plot
link.PC <- ggplotly(akl.PCA, tooltip=c("label1")) %>%
  layout(dragmode="select") %>%
  highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T)

# SharedData for the decile plot
sdDecile <- SharedData$new(
  data.frame(School=akl$School, Decile=as.factor(akl$Decile)), 
  key=~School, group="nceaPCA") 

decile.p <- ggplot(sdDecile) +
  geom_jitter(aes(y=Decile, x=1, colour=Decile), width=0.1, height=0) +
  labs(x="Decile", y="") +
  scale_x_continuous(limits=c(0.7, 1.3)) +
  #scale_y_discrete(position="right") +
  theme(
      panel.border=element_rect(colour="grey", fill=NA),
      panel.background=element_blank(),
      legend.position="none",
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())

link.decile <- ggplotly(decile.p, tooltip="none") %>%
  layout(dragmode="select", yaxis=list(side="right"), margin=list(r=30)) %>%
  highlight(on="plotly_select", off="plotly_deselect", color="blue", persistent=T) 

subplot(link.PC, link.decile, widths=c(0.7, 0.3), margin=0, titleX=T, titleY=T)
```

```{r}
sdAkl <- SharedData$new(akl[2:5], group="nceaPCA")
Akl.pairs <- ggpairs(sdAkl)
ggplotly(Akl.pairs) %>%
  layout(dragmode="select") %>%
        highlight(on="plotly_select", off="plotly_deselect", color="blue", 
                  persistent=T, dynamic=T)
```

#### NZ schools
```{r}
# Static plot
ncea_PCA(nzqa) + ggtitle("Achievement of NZ schools in 2016")
```

Merge with other demongraphics on schools
```{r, eval=FALSE}
# Download file from internet (updated September 2017)
schools <- read.csv("https://www.educationcounts.govt.nz/__data/assets/file/0003/62571/Directory-School-current.csv", skip=3, header=T)
# Tidy up variable names
raw.cols <- readLines("schools.csv", n=4)[4] # Keep the fourth row only
colnames(schools) <- gsub("[^a-zA-z0-9]", "", strsplit(raw.cols, ",")[[1]])
# Subset relevant variables
schools <- schools[c(2, 10, 15, 16, 33:39)]
# Keep only schools with secondary level students
secondary <- schools %>%
  filter(!((SchoolType=="Full Primary")|(SchoolType=="Intermediate")))

# Merge with NZQA data
nzqa.sch <- merge(nzqa, secondary, by.x="School", by.y="Name") # 350 schools (left from 408)
# Change ethinicity counts to proportions
# MELAA refers to Middle Eastern/Latin American/African
nzqa.sch[12:17] <- sapply(nzqa.sch[12:17], function(x) {round(x/nzqa.sch$TotalSchoolRoll, 2)})
nzqa.sch$Other <- 1 - Reduce("+", nzqa.sch[12:16]) 
head(nzqa.sch)
```

