---
title: "Code-based open-source software for teaching interactive data visualisation"
subtitle: "Mid Semester 2 Report"
author: "Shan-I Lee"
date: "8/26/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# For tidying of NCEA data
library(tidyr) 
library(dplyr)
library(GGally)
library(plotly)
library(MASS)
library(tourr)
#library(gridExtra)
```

## Introduction

This report will discuss the developments since last semester on using code-based open-source software for teaching interactive data visualisation. The insights gained from developing an exemplar of interactive techniques applied to data analysis, will form the basis of discussion. Implications for teaching, such as the choice of techniques, software and datasets will then be discussed.

### Development of a comprehensive exemplar 

A narrative on how ideas for the exemplar emerged and changed over its development will be outlined and examined with respect to the insights gained in the process.

#### The NCEA dataset

The motivation to develop an interactive exemplar for cluster analysis emerged from reading literature on the topic, as well as finding "real" data for which it was of interest to see if there was any such underlying structure. Data on the performance of New Zealand schools in the National Certificate of Educational Achievement (NCEA), at the four qualification levels, Level One, Two, Three (L1, L2, L3) and University Entrance (UE), were obtained from the New Zealand Qualifications Authority (NZQA) website. Information on the school decile, region and a "small" cohort warning, were also provided in the data. The decile rating is a measure of the general income level of the families of students attending the school. The socio-economic background of students increases as the decile increase from one to ten. A handful of schools have a decile rating of zero, due to unique circumstances that make them exempt from the socio-economic measure. The achievement rate of a school for each qualification level was quantified in a few ways. The achievement indicator chosen for this analysis was the proportion of students at the school who were successful in obtaining the qualification level, given that they were entered in enough standards to have the opportunity to earn the qualification in the 2016 school year. This is referred to as the "Current Year Achievement Rate" for the "Participating Cohort" by the NZQA (see <http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/NZQA-Secondary-Statistics-Consolidated-Data-Files-Short-Guide.pdf>). 

Only schools with achievement indicators across all four qualification levels were retained, thus reducing the dataset to 408 schools from around New Zealand. The focus of analysis will be on its subset of 91 Auckland schools, but the New Zealand dataset of 408 schools will be used to demonstrate how interactive techniques can be useful as the number of observations increases.

The focus of analysis will be on the Auckland subset because it is less affected by the unreliability of small sample sizes. The NZQA indicator of a "small" cohort was at a very low threshold of fewer than five candidates for any qualification level. Being the most populated city in New Zealand, Auckland has many of the larger schools, but there may still be some schools left in the analysis that have less than 30 candidates entered in a qualification level. The first few observations from the data set of 91 schools in the Auckland region are shown below.

```{r, echo=FALSE}
nzqa2016 <- read.csv("http://www.nzqa.govt.nz/assets/Studying-in-NZ/Secondary-school-and-NCEA/stats-reports/2016/Qualification-Statistics-School-2016-29032017.csv")
# Drop vars that will not be used (eg. cumulative achievement)
nzqa2016 <- nzqa2016[,-c(1,8,10)]
names(nzqa2016) <- c("Decile", "Region", "School", "Year", "Qualification", "Achieve_participate", "Achieve_roll", "Small_sch")
levels(nzqa2016$Qualification) <- c("L1", "L2", "L3", "UE")
# Subset to use only Year 11 with Level 1, etc
nzqa <- nzqa2016 %>% filter(((Qualification=="L1") & (Year==11)) | 
                          ((Year==12) & (Qualification=="L2")) |
                          ((Year==13) & (Qualification=="L3")) | 
                          ((Year==13) & (Qualification=="UE"))) %>%
  # Reshape so that each row represents an observation (a school)
  # Current.Achievement.Rate.Participation kept for analysis only
  spread(Qualification, Achieve_participate, fill=0) %>%
  group_by(School) %>%
  summarise_at(c("L1", "L2", "L3", "UE"), sum) %>%
  inner_join(nzqa2016[, c(1, 2, 3, 8)]) %>% # Add Decile and Region and Small_sch variables
  distinct() %>% 
  filter(!((L1==0)&(L2==0)&(L3==0))) #Remove schools with 0% achievement rate for all levels

# Function to replace 0% with NA
zeros <- function(col) {
  replace(col, col==0, NA)
}

nzqa[2:5] <- sapply(nzqa[2:5], zeros)
# Remove schools with 'small cohort' warning (obscures pattern in non-small cohorts).
nzqa <- nzqa[nzqa$Small_sch=="",] # 439 school left
nzqa <- nzqa[, -8] # Remove Small_sch var
# Remove schools with any NA values 
nzqa <- nzqa[complete.cases(nzqa),] # 408 NZ schools
# Subset Auckland schools only
akl <- as.data.frame(nzqa[nzqa$Region=="Auckland", -7]) # 91 AKL schools
rownames(akl) <- akl$School # Need for tooltips in tour
head(akl[-1], n=3)
```

#### Static visual analysis

A question that naturally arises from the NCEA data is whether a school's performance is related to its decile rating. 

The pairs plot in Figure 1 shows the achievement rates at L1, L2 and L3 have a weak relationship with decile rating, but the positive correlation is strong at UE. There appears to be an increasing "lower bound" to achievement rates for L1, L2 and L3, as decile increases, but there is a lot of scatter above this boundary. In the bivariate scatterplots we can also see the spread of achievement rates varying across decile groups. The variation in achievement rates decreases as the decile increases (from one), across all qualification levels. We can see many schools approaching the maximum 100% achievement rate, for L1, L2 and L3, hence it is not surprising to see their univariate distributions are skewed to the left in Figure 2. The distribution of achievement rates for UE is less skewed and hints at two possible groupings. Furthermore performance across the qualification levels appear to be positively correlated, especially between L1 and L2. Hence the low-dimensional plots indicate non-normality, unequal spread between groups and multicollinearity.

##### Figure 1: Pairs plot for NCEA data on Auckland schools
```{r, echo=FALSE}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x, y)
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(akl[-1], lower.panel=panel.cor)
```

##### Figure 2: Univariate distributions for NCEA data on Auckland schools

```{r, echo=FALSE}
NCEA_hist <- function(x, title) {hist(x, xlab="Achievement rate", main=title)}
layout(matrix(1:4, byrow=1, ncol=2))
NCEA.hists <- mapply(NCEA_hist, akl[2:5], colnames(akl[2:5]))
```

#### Multivariate visual representations

The pairs plot in Figure 2 provided a glimpse into the multivariate distribution of achievement rates across the four qualification levels. The parallel coordinates plot (PCP) shown below in Figure 3 allows us to further compare the multivariate distributions of achievement rates for different decile groups, as well as identify high dimensional clustering and outliers.

The ordering of axes in a PCP greatly affects the quality of the graphical analysis (Unwin, 2015). In the case of the NCEA data, the natural ordering of the four qualification levels by difficulty, conincides with the recommendation from Cook and Swayne (2007) to order the axes based correlation. In addition, Unwin (2015) highlights the layering of colours also needs to be considered carefully, since the last group assigned a colour will dominate the other lines.

The positive relationships previously identified in the pairs plot, should translate to parallel lines between axes in the PCP, as opposed to a "criss-cross" pattern for negative correlation. The static plot in Figure 3 questions whether the positive relationships hold true for schools with low achievement rates and in some decile groups. The higher decile schools in Auckland appear to dominate the high achievement rates across all qualification levels, while lower decile schools are inconsistent with each other in terms of their performance across the levels. Although there are only 91 observations (lines), it is quite difficult to identify even "ball park boundaries", on the 11-point decile scale, to distinguish between "higher" and "lower" decile schools when describing possible patterns.

##### Figure 3: Parallel coordinates plot for NCEA data on Auckland schools
```{r, echo=FALSE}
# Plot with consistent labels
ggpcp <- function(x, a=1) {
  ggparcoord(data = x, columns = 2:5, scale = "uniminmax", 
             mapping=aes(colour=as.factor(Decile), label=School, label1=Decile), alphaLines=a) +
  labs(x="Qualification level", y="Achievement rate", colour="Decile")
}

ggpcp(akl) + ggtitle("Achievement of Auckland schools in 2016")
```

The following two plots demonstrate how alpha blending can help minimise the effects of overplotting as the number of observations increase. It is easier to check whether the patterns identified in Auckland schools extend to the 408 schools across New Zealand, using Figure 5 where alpha blending is applied, rather than Figure 4. The performance of high achieving lower decile schools is less "drowned out" by the dominance of their higher decile counterparts, when alpha blending is used.  

##### Figure 4: Parallel coordinates plot without alpha blending
```{r, echo=FALSE}
ggpcp(nzqa) + ggtitle("Achievement of NZ schools in 2016")
```

##### Figure 5: Parallel coordinates plot with alpha blending
```{r, echo=FALSE}
nz.pcp <- ggpcp(nzqa, a=0.5) + ggtitle("Achievement of NZ schools in 2016")
nz.pcp
```

#### Leveraging static plots with interactivity

Unwin (2015) advocates for the use of colour and interactive ordering of axes, in order to maximise the effectiveness of parallel coordinates plots. Similarly MASS (???) also suggests that without interactivity, such as identification and linked brushing, parallel plots are largely difficult to use. Figure 6 demonstrates how adding interactive filtering helps to further reduce the problems with overplotting and allows direct comparison between selected decile groups.

One of the strengths of parallel coordinates plots is in identifying multivariate features, such as outliers (Cook and Swayne, 2007). Figure 3 suggests a school's performance can be unusual in two ways, either it performs inconsistently to the bivariate correlations between the qualification levels (this was previously noted as typical of "lower" decile schools), or its achievement rates across the levels are unusual compared to the rest of its decile group. The latter becomes difficult to see for the New Zealand dataset, in the static plots (Figures 4 and 5), even with alpha blending applied. The filtering feature of Figure 6 overcomes the problems caused by overplotting by allowing the user to isolate the distribution of each decile group (via a double-click on the legend). Furthermore the interactive tooltip feature enables the possible outliers to be identified by school name, or observation number, as shown in Figure 6. 

##### Figure 6: Parallel coordinates plot with interactivity

```{r, echo=FALSE}
ggplotly(nz.pcp, tooltip=c("label1", "x", "y", "label"))
```

The parallel coordinates plot in Figure 3 suggests that patterns of performance across decile groups, if they exist, are difficult to distinguish at the multivariate level for Auckland schools. 
Principal component analysis provides an...


##### Figure 7: Plot of first two principal components for Auckland schools
```{r, echo=FALSE}
# Static PCA plot
# Function for PCA and plot
# scale.factor is an arbitary value that scales the loadings axes so that they can be on a comparable scale as the standardised PCs (scores). 
# nudge argument also depends on the range of PC1 (used for enhancing the legibility of text labels on loadings axes).
ncea_PCA <- function(df, scale.factor=20, nudge=-0.2) {
  # Perform PCA
  pca <- prcomp(df[2:5], scale.=T)
  # Explained variance
  exp.var <- round(pca$sdev^2/sum(pca$sdev^2)*100, 1)
  # Scores (rotated principal components)
  scores <- data.frame(df[1], t(t(pca$x[, 1:2])*(pca$sdev[1:2]^-1)))
  scores$Decile <- as.factor(df$Decile)
  #scores$Decile <- as.factor(as.character(df$Decile))
  #scores$Decile <- factor(scores$Decile, levels(scores$Decile)[c(1, 2, 4:11, 3)])
  axis.limit <- c(-round(max(abs(scores[2:3])), 1), round(max(abs(scores[2:3])), 1))
  # Variable axes (loadings)
  lambda <- pca$sdev[1:2]/sqrt(nrow(df)-1)
  loadings <- data.frame(varnames = rownames(pca$rotation), 
                              t(t(pca$rotation[, 1:2])*lambda*scale.factor))
  # Plot of first to PCs
  p <- ggplot(loadings) + 
    geom_text(data=scores, aes(x=PC1, y=PC2, label=Decile, 
                                     colour=Decile, label1=School)) + 
    geom_segment(aes(x=0, y=0, xend=PC1, yend=PC2), colour="grey35") +
    geom_text(aes(x=PC1, y=PC2, label=varnames), colour="grey35", nudge_x=nudge) +
    #coord_fixed() +
    labs(x=paste("PC1 (", exp.var[1], "% explained var.)", sep=""),
         y=paste("PC2 (", exp.var[2], "% explained var.)", sep="")) +
    scale_x_continuous(limits=axis.limit) +
    scale_y_continuous(limits=axis.limit) +
    theme(
      panel.border = element_rect(colour="grey", fill=NA),
      panel.background = element_blank(),
      legend.position = "none")
  return(p)
}
# Static plot
akl.PCA <- ncea_PCA(akl) + ggtitle("Achievement of Auckland schools in 2016")
akl.PCA
```

The static plot in Figure 7 highlights the usefulness of being able to directly identify unusual observations. Which schools are the two unusual decile 9 and 10 schools? The interactive tooltips in Figure 8.

##### Figure 8: Plot of first two principal components with interactivity
```{r, echo=FALSE}
ggplotly(akl.PCA, tooltip=c("label1"))
# Linked brushing of PCA and decile plot
# Will need to add akl to sharedData first.
# Brush decile 6 to 8 schools and then brush the small group in the "biplot"
sdAkl <- SharedData$new(akl, key=~School, group="aklPCA")
# SharedData for the factors plot
Fdataset <- data.frame(School=akl$School, Decile=as.factor(akl$Decile))
sdF <- SharedData$new(Fdataset, key=~School, group="aklPCA") 

decile <- ggplot(sdF, aes_string(x=names(Fdataset)[1])) +
        geom_jitter(aes(y=Fdataset$All, label=ID), 
                    width=0, height=0.25) +
        labs(title="The first factor is displayed") 

ggplotly(decile, tooltip=c("x", "y", "label", "label1", "label2"), height=400, width=600) %>%
        layout(dragmode="select") %>%
        hide_legend() %>%
        highlight(on="plotly_select", off="plotly_deselect", color="blue", 
                  persistent=T)

```

### AKL figure
```{r}
ggplotly(akl.PCA, tooltip=c("label1"))
```

Show how biplot above is related to initial orthogonal projection of tour (see Cook)
Rationale for launching tours from these initial bases:
"The first k principal components span a subspace containing the 'best' k-dimensional view of the data" (p.303 Mass)

```{r}
# NZ schools
nz.PCA <- ncea_PCA(nzqa, scale.factor = 50) + ggtitle("Achievement of NZ schools in 2016")
nz.PCA
```


#### Dynamic and interactive multivariate visual representations
Tours provide another visual perspective that is not restricted to orthogonal projections of the multivariate space. Wickham et al. (2015) highlight interactive visuals, such as tours, are more effective for exploring high-dimensional object than static plots. In addition, Cook and Swayne (2007) emphasise the important role of interactive graphics in interpreting, assessing and refining models obtained from numerical methods. Visuals in general allow us to "get under the hood" of black-box numerical methods to gain a better understanding of the process and the solutions produced (Wickham et al. 2015). A guided tour embodies the fusion of a numerical method, projection pursuit, in a dynamic visualisation. 

Cook and Swayne (2007) used the `crabs` dataset to demonstrate how tours can be used effectively to perform cluster analysis when the clusters are clearly separated. The dataset consists of five physical measurements for 50 Australian female and male crabs of two colour forms, blue, `B`, and orange, `O`. This dataset and interactive techniques demonstrated by Cook and Swayne (2007) using `ggobi` helped to develop the guided tour shown in the final exemplar. Based on the analysis so far, the Auckland schools dataset is unlikely to contain distinct clusters, but the dynamic nature of tours may help shed more light on its complex multivariate distribution. Hence the dynamic and interactive environment of `ggobi` was explored to gain ideas for the exemplar. 

#### Insights from using new interactive software

`ggobi` is an open-source software that showcases many interactive visualisation techniques. The flexibility and speed at which techniques can be applied in `ggobi` is yet to be paralleled by more recently developed interactive tools. For instance, linked brushing of "n-to-m" enables a variety of plots to be interactively linked in `ggobi` (Cook & Swayne, 2007). However the `SharedData()` function in the `crosstalk` package is limited to one-to-one brushing and hence currently unable to be applied to aggregate plots (RStudio, 2016). 

Similarly tours are launched with ease via the graphical user interface (GUI) in `ggobi`. However the absence of code to document explorations makes it challenging to share and replicate findings found via interactive visual exploration in `ggobi`.  Furthermore the desire to review previous projections when viewing tours, was identified as another limitation. To some extend the `rggobi` package addresses the issue of code documention. Demostrations of dynamic data analysis in `ggobi` and `Mondrian` are often shared via pre-recordings. For example the analysis of the Tour de France using `Mondrian` by Theus (2016). Although the recordings are dynamic, the level of interactivity is limited to rewinding. The stochastic nature of tours begs for more user interaction than as a post-event observer. Being able to visually compare and launch several "live" tours on demand, places the signal of random process in the context of the inherent variation (Wickham et al. 2015).

#### Interactive techniques used in the exemplar

The development of the guided tour in the exemplar began with static plots of the tour projections and axes positions, synced to an user controlled animation slider. Initially, only visualisations of single tours were considered. Initial trials of the single tour animation using the `crabs` dataset, did not seem to identify the separation between the two colour forms discussed by Cook and Swayne (2007). After further investigation it was found the ordering of the variables in the dataframe determined the orthogonal starting point used by the `tourr` package. The choice of starting point is very important in a guided tour, since a stochastic process is used to search the neighbourhood for a view that is more "interesting" than any previously seen, as judged by the pursuit index. If after a certain number of attempts no such view is found then the tour ends. Consequently a guided tour can get "stuck" at a local maxima, hence the need to examine tours from different starting points (Wickham et al. 2011). In order to maximise the tour coverage, orthogonal projections of all possible pairwise combinations of the variables were used to create different starting points in the guided tour of the exemplar. 

The final projections and axes positions of the different tours (to a maximum of five) are visually summarised in a matrix of plots. This visual representations of members of a collection of a model, enable deeper insights than observing only one model (Wickham et al. 2015). The matrix shows the final projections of guided tours that identify the same clusters (e.g. the gender split) are sometimes related by 2D rotation. Furthermore the final axes positions indicate which variables are consistently more prominent in the views showing certain clusters.

The projection pursuit index plot in the exemplar shows how visual representations can provide a way to make the large volumes of numerical output meaningful and useful. When applying the exemplar to the `crabs` dataset we can see the `holes` indices reached by different tours fall roughly into two groups. The group of lower index values generally correspond with final projections that show a subtle distinction between genders, while final projections with higher index values show a more defined separation between orange and blue crabs. Cook and Swayne (2007) demonstrated using interactive techniques how numerical methods are ineffective in separating the genders of small crabs. 

At times one of the guided tours in the exemplar will result in a higher final index value than the rest. The corresponding tour projection shows three clusters with the female orange crabs almost separated without overlap from their male orange counterparts, alongside the blue crabs as a single group. This view suggests the blue crabs are smaller and hence may contribute more to the overall difficulty in separating the genders. The numerical approach of model-based clustering examined by Cook and Swayne (2007, p.117) produced a model identifying three clusters as well but further exploration of this model was not undertaken since the focus was on separating the four colour-gender classes.

The projection pursuit index plot in the exemplar not only compares the index values reached by different tours, but also gives insight into how index values relate to their projected views. It allows the examination of the process underlying projection pursuits and not only the final model, as advocated by Wickham et al. (2015) when applying numerical methods. 

A guided tour with the `holes` index was also applied to the Auckland schools data. As expected there were not any clearly separated clusters. However the projections from orthogonal principal component axes suggest a slight separation of a small group of schools from the majority. Brushing the smaller group in the tour projection view shows these points correspond to the scattered "tail" of generally lower achieving schools shown in the pairs plot. The linking with the plot showing classes of categorical variables, in this case deciles, shows these schools are generally decile five or below, with the exception of a couple of surprisingly high decile schools. It may have been possible to identify these high decile multivariate outliers in the parallel coordinates plot, but the tour provides extra information on which schools they are more similar to and hence a better understanding of why they are unusual. Linked brushing enabled patterns identified in complex high dimensional space to be related back to the original variables.

### Implications for teaching

The motivation to learn how to write code to enable interactive techniques is likely to depend on how useful the techniques are perceived relative to the learning curve required. There is a natural temptation to find a "one-stop-shop" package or software, but recent open-source developments lean towards different packages being used in collaboration. The exemplar required the use of three packages (`plotly`, `crosstalk` and `Shiny`) in order to achieve the interactive techniques and create the components desired.

The addition of one line of code to enable tooltip identification on the static plot of the New Zealand schools dataset, demonstrates the ease with which this interactive tool can be applied (see code for Figures 5 and 6). Furthermore the usefulness of instant identification, without cluttering the visual with static text, easily outweighs the minimal learning curve required.

Linked brushing requires more effort to learn and apply, but the technique epitomises Aristotle's quote that "the whole is greater than the sum of its parts". The insights gained about NCEA performance for Auckland schools would have been difficult to see without linked brushing of the tour projections with the pairs plot and the decile factor plot. Both tooltip identification and linked brushing can add value to other interactive techniques, such as dynamic tours. Hence it is not surprising to see the availability of their functionality in both "classic" and more recently developed, interactive software.

On the other hand interactive techniques like deleting or dragging points appear to be less general in their use and hence less frequently enabled in software. The commercial software `Alteryx` allows points to be dragged in its `Network Analysis` tool, but not in its other applications (`dashboards`). In comparison deletion and changing values via any scatterplot or parallel coordinates plot is possible in `ggobi`, but with a caveat to the user (Cook and Swayne). 

There appears to be a spectrum in terms of the level of customizability of interactive software and hence the flexibility they allow for taking a novel approach to applying interactive visualisation techniques. On one extreme are the fixed commerical GUIs of `Alteryx` and `Tableau` that make some of the decisions on how and when interactive techniques should be used for the user. This design is intended to make interactive techniques easy and fast to apply, which is a key selling point for the two commercial products. The open source `trelliscope` package uses code to launch its interactive userface, hence in some way similar to `Shiny`, but user customization of the interface is limited. However `trelliscope` is a prime example of how a highly effective static plot, the trellis plot, can be further leveraged with the addition of interactive techniques like linked brushing and filtering (Hafen, 2017).

In contrast other recently developed open-source software for interactivity, allow the user to combine interactive techniques in various ways and hence to a range of contexts (for examples see the `Shiny User Showcase`: <https://www.rstudio.com/products/shiny/shiny-user-showcase/>). The trade-off for this flexibility is the additional learning curve, time and effort required to write code to access these interactive tools.

Interestingly "older" open-source software like `ggobi` and `Mondrian` seem to be a combination of the two different approaches taken by more recently developed software. They both provide a GUI and do not allow code-based documention as stand-alone software. However the depth and breadth of interactive tools available in `ggobi` enable graphical data analysis to be applied to a vast range of problems and datasets, as demonstrated by Cook and Swayne (2007). The relatively recent development of the package `rggobi` enables the benefits of sharing and documenting explorations in `ggobi` via `R` and with code.

Recent developments in open-source interactive software (`shiny`, `crosstalk`, `plotly`) allow for tools to be be shared and reproduced easily via code documentation. In contrast explorations carried out in `ggobi` or `Mondrian` are more difficult to "instantaneously" reproduce. Furthermore code documentation allows for reuse and customisation. With this in mind users are able to produce either "bespoke tools"" or those for more general purposes. The temptation to add more and more interactive details tends to pull an interactive tool towards the bespoke end, while the desire to reuse and maximise the return from the amount of time and effort invested in creating the tool, provides motivation to keep its purpose more general. The exemplar leans towards the latter, but is not at the level of complexity of a R package. The collection of interactive techniques and components can be used as it is, or modified easily to explore clusters in another dataset. If the code for the exemplar was "hard coded" to as specific dataset, either the `crabs` or NCEA data, then the programming skills required would be less demanding. Allowing students to choose how "general purpose" they wish to make their interactive tool, provides a way to cater for a range of programming expertise and focus assessment on the quality of the visuals and interactive techniques applied. 

The use of graphics in data analysis is generally used for exploratory purposes, alongside numerical methods and as an effective tool for communication (Unwin 2015). The exemplar suggests the educational value and insights obtained from leveraging visuals with interactive techniques, provide further support for students to learn and apply interactive visualisation in their data analysis process.

Exposing students to the breadth and depth of interactive graphics in `ggobi` enables them to focus on the interactive techniques being applied. Combined with learning how to write code to achieve commonly used techniques like identification and brushed linking, increases the chance of students applying interactive techniques to future projects.

Lastly a mixture of "tried and true" datasets with novel "real" data provides a balance of guidance and curiosity to support the learning of interactive techniques for data analysis. In the exemplar the NCEA data provided motivation, while the `crabs` dataset prompted further refinement of the interactive techniques and components used in the exemplar.

#### Conclusion

The development of an exemplar for applying interactive techniques to data analysis identified how the use of different datasets can provide motivation and guidance. Furthermore the experience provided an opportunity to explore and hence more thoroughly understand, abstract and complex theory previously encountered in literature. The availability of open-source software that is relatively easy to learn, supports the teaching of interactive visualisation techniques. Furthermore the advantages of encoporating graphics in data analysis can be leveraged with the application of interactive techniques to conventional static plots.
