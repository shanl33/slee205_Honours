---
title: "Key Notes"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## References
**How to cite comments on package if author not clear? ie. ggvis.**
**Should use author (Hock for animint, Seivert for plotly etc..) to reference comments?**
+ plotly <https://github.com/ropensci/plotly>
+ crosstalk <https://rstudio.github.io/crosstalk/authoring.html>
+ Shiny
+ ggvis: <http://ggvis.rstudio.com/>
+ Mondrian: <http://www.theusrus.de/Mondrian/>
+ Animint: <https://tdhock.github.io/animint/#introduction>
    - "Draft version" of unpublished paper on github. Retrieved from: <https://github.com/tdhock/animint-paper/blob/master/HOCKING-animint.pdf?raw=true>
+ Trelliscope: <https://hafen.github.io/trelliscopejs/#why_trelliscope>
+ Need to reference all packages used in report (eg. tidy?)
+ Use: knitr::write_bib(c("knitr", "stringr"), "packages.bib", width = 60) to generate bibtex file
+ Add to YAML: bibliography: ["HonourProj.bib", "packages.bib"]
+ May also need to add this in YAML so the packages (which are not cited explicitly) show up:
+ nocite: | 
#  @R-bookdown
+ Delete or keep pipeline in HonourProj.bib?
+ Need to explain what a PCP is?

## Report questions
+ Use examples to explain what the techniques are in the survey part? If so use crabs to do it?
+ In survey of software can just focus on plotly, Shiny and Crosstalk? (Can include only these in the table and no others?) But mention ggobi (not code based), trelliscope (very specific application), both more GUIs orientated rather than code.
* Focus on comparisons between the 3 packages instead? In terms of ease and level of modification possible.
* In survey of techniques can focus on unpacking the three techniques: subset selection, linked brushing and tours? Mention identification, but not much to discuss.

# To do's:
+ Check all points are demonstrated in part 2.

NCEA - use tour on cmass and link to PCP. 
Explore neighbourhood of PCA's for interesting views.
See if schools have a common structure (high L1, high L2, low L3, low UE?). Not focus on using decile to explain structure. More complex than that. EDA forces us to see what we don't expect. Started with the intention of exploring a relationship between decile and NCEA achievement, but gained insights that went further than using a single factor to describe complex patterns. Started with a relatively surface question that lead to more indepth questions as a result of applying interactive techniques in EDA. Would this have been possible without the use of visuals? Interactive techniques?

If using ggparcoord - cannot use linked brushing in plotly at all (only default tooltips and legend filtering possible).  Need to explicitly 

# Uploading shiny app
Retrieve key on shiny account (linked to github)
Open app, run it to check and can use blue "Publish" button or run commands:
library(rsconnect)
deployApp()

## github pages
+ Write the yaml in RStudio and just save as .yml
+ Follow these instructions <http://nickstrayer.me/RMarkdown_Sites_tutorial/>
+ Stick to the same file names.
+ Can have as many pithub pages as you want.

## Knit to pdf without plots being annoying
Put the following in the "Yaml" so that the figures won't float.
And put the fig.pos="H" in the chunk options.
---
header-includes:
- \usepackage{float}
---

## Questions
* Can we be more "off the cuff" in the presentation? (ie. don't need to cite everything, some opinion-based comments)
* Report itself is submitted in PDF format, but with supporting documentation (Rmd and files). Can't submit as html? (Static screen shot of filtering with PCP using plotly's default legend needed then).

### Answered
* Is it sensible for `plotly` plots to render faster than `ggplot2`? Yes, plotly is lower-level to the javascript library it uses than using `ggplot()+ggplotly`.
    + `plotly` object keeps up better with animation at a faster speed (300 millisecond per animation step)
* Using `plotly` alone (without `shiny`) has the advantage of producing a "standalone html". Why is this an advantage? Easier to share, no need to host on an external server, don't need R running in the backgroun if you don't want it to.
* Is `cranvas` worth investigating? 
    + NO, difficult to install and appears to be not in development anymore.
    + Will not exceed ggobi's capabilities.
* `Acinonyx` R package is a possible successor for `iplots`? YES
* `rggobi` and `iplots` packages are installed on postgrad uni lab machines.
    + Cannot install `iplots` on my personal laptop (cashes RStudio) 
    + NO `Describe Display` plugin in GGobi on the uni machines.
* Do I have to cite a specific source when making "common statements"? quote from someone or from a study (or via a demonstration)
    + eg. Order of vars for a parallel coord point is impt?
    + Choice of file type for image (raster vs scalable)
*'googleVis' bought Hans Rosling's stuff. 
    + R package to connect w it.
*`ggiraph` R package, a bit like plotly but allows more custom control over interactive techniques.
    + Adds interactive techniques to ggplot2 plots.

## To do's
* See if projection pursuit values are saved (invisibly) in output from tourr, if so use it to save running time for app. (Profiling shows the index calc in code takes some mem and time, otherwise the time is mostly being chewed up by the stochastic process within tourr fns)
* Return to original intention (an interactive visual to analyse a heirachical clustering algorithm) to show if can modify current app easily and make it a worthwhile, lasting investment? 
* Tour function (using `tourr` package)
    + PCP of linear combination of variables for the PC's used in the tour (Xs on axes, PCs are the obs, coloured by magnitude of PC in projection). The PCP will help to relate the PCs used in tour with the X vars from the context.
* Create a dendrogram in ggobi that can be brushed (see Paul's notes from 20 June). Brushed linking of line segments with parallel plot demonstrated in Cook p.110.
* Look at other data visualisation courses (see Reading List section)
* Shiny sliders:
    + cycling of combinations of possible vars for scatterplot and mosaic plots (2 to 3 vars only)
* Use interactive environments in Shiny to record interactions and send them back to R (and back again?). 
    + See *Interactive environments in Shiny* section

### NCEA data
* See: <http://www.nzqa.govt.nz/studying-in-new-zealand/secondary-school-and-ncea/find-information-about-a-school/secondary-school-statistics/consolidated-files/data-files-for-2016/>
* Bi-modal distribution in L3 (and slightly L2).
    + Investigate clustering based on L3 alone?
* Aim: Partition student achievement data according to the decile of the school.
* Cluster analysis: Use a numerical method to model clusters, then use visualisation to interpret and analyse clusters.
    + Heirarchical clustering algorithm using Euclidean distances and average linkage identified 4 clusters and two overlapping clusters. The smaller cluster was relatively low-achieving and consisted of the lower tail of the univariate distributions for each level of achievement. All schools except 1 in this cluster was from decile 6 or below. There is no clear separation between the two clusters in any univariate distribution and the 2D tours looked at so far.
* Multicollinearity is a big issue! Don't include all the levels, since they are measuring the same thing! (avoid using many clustering variables, because
the chance of the variables being similar increases. Multi-collinearity = difficult to segment, identify clusters, Corr>0.9 = problems).
* Whether you use correlation or one of the distance measures depends on whether
you think the relative magnitude of the variables within an object (which favors
correlation) matters more than the relative magnitude of each variable across
objects (which favors distance). However, it is generally recommended that one
uses correlations when applying clustering procedures that are susceptible to outliers,
such as complete linkage, average linkage or centroid (see next section).


#### To do:
* Re-analyse with the 6 clusters (using L1, 2, 3 AND UE).
* Use correlation distance instead of Euclidean to identify clusters that a similar in structure.
* Investigate bi-modal distn in L3.

## Statistical methods
### Cluster analysis
* Cook (p.126): Uses of graphics in cluster analysis to...
    + Identify clusters graphically (sometimes a graphical approach alone may be sufficient)
        - Works well when groups are clearly separated.
        - No need for assumptions about equality of variance or linear boundaries.
        - Does not work well when clusters overlap or purpose is to partition data (regardless of whether clusters exist).
        - Numerical methods are preferable if partitioning is the goal and then graphics can be used to interpret and evaluate the model (see below).
    + Interpret models resulting from (numerical) algorithms, by colouring with cluster membership and using scatterplots, parallel coordinate plots, area plots and dendograms, to check the clustering is sensible.
        - How many clusters are there? How big are the clusters?
        - What shape are the clusters? Do they overlap?
        - Which variables contribute the most to the clustering?
        - Can the clusters be qualitatively described?
    + Assess (or compare and/or refine) models from algorithms.
        - Check assumptions about distributions 
        - For self-organising maps: Tours can help identify problems with the fit (that would not be picked up in a 2D map view eg. when map wraps in on itself and makes points close to each other seem apart),
        - Confusion table with linked brushing to plots (such as a tour projection) allow mismatches and agreements between methods to be explored.
* Cluster analysis 'tends to produce hypotheses rather than testing them' (p.107). Hence cluster analysis is an exploratory technique, that may lack 'formal validation' but it is powerful in data simplification. 
* Cluster analysis vs classifying: cluster analysis is unsupervised while classifying assumes an underlying structure of membership to certain groups (?)

### Principal Components
* `princomp()` and `prcomp()` are two functions in R for obtaining PCs. `tourr` package uses the latter. The signs of the components are random. We are interested in the differences in size of coefficients, where direction of difference doesn't matter. 
* When coeffs are close to zero they are dropped in some methods (eg. `princomp(crabs[,4:8])` drops some coeffs while `prcomp()` will return a coeff for all vars even when close to zero. A threshold can be entered as an argument).
* See MASS book pg.357 for a good example of how to interpret the coeffs of PCs.

### 2D Tours
* `crabs` dataset could be a good example to demonstrate the use of guided tours optimising the holes index to identify group structures in the data.
    + Using PC1 and PC2 for the starting projectcion basis brings out the gender separation and using PC2 and PC3 (??) highlights the species separation (need to check this) since gender separation is more defined than the species separation?? Also need to check how the separation into 4 (sex-species) groups is seen in the tours.
    + A good dataset to demonstrate the usefulness of visualising and tracing the random tour paths of several tours. 
* Which combination will result in smoother animation: (`plotly`+`shiny`) or (`plotly`+`crosstalk`)?
    + They appear to be the same 'speed' but the tour plot and slider are more in sync and smoother, when using (`plotly`+`crosstalk`). Other advantages of using (`plotly`+`crosstalk`):
        - Standalone html viewer.
        - Can still use R while interacting with the visual.
        - Easy to link multiple plots and initiate brushing from any of the linked plots.
        - Can use `html widgets` to achieve the same interactions provided by `shiny` inputs (sliders, buttons, etc)
    + For `crosstalk`: `animation_opts(33)` seems to be the same speed as `animation_opts(10)`. Maybe since speed maximised.
    + For `shiny`: Can adjust `animate = animationOptions(400)` argument for input slider, to be more in sync.
    + Can `subplot()` be used with (`plotly`+`shiny`)? YES
* (`plotly`+`crosstalk`): Use Firefox browser if have multiple linked plots. Some other browsers may not show all plots.
* Guided tour = combining grand tour and projection pursuit. This results in choosing new projections with respect to maximising an index of interest, rather than at random [^3].

#### My function for 2D Guided Tours
##### Goals / Intentions:
* Model "good" statistical practice.
    + Choice (and design) of plots, interactive tools, summary statistics, default values for arguments.
    + Give reasons for the choices made based on literature and theory.
* Useful for analysing a range of datasets where unsupervised cluster analysis is of interest.
    + Provides a framework/structure but avoid being overspecific and prescriptive.
    + Allows for further modification and extention (code-based).
    
##### Reasons for choices
* Plot for projection pursuit index:
    + Similarities with Fig 14 on p.216 [^3]:
        - Link index value with the 2D tour projection.
        - Use the index plot to compare local optimal projections from different tours and see if they are consistent. (An example of a wider theme of: Using visuals to gain insight into the consistency of random processes. eg. tours, cross-validation,..).
        - Visualising the path of projection matrices in covering the data space is difficult since it involves a p-D hypersphere [^3]. To do: See [^4] and try the hypersphere interactive visualisation describe in `ggobi`.
    + Differences with Fig 14 on p.216 [^3]:
        - Use of principal components "shortcuts" the guided tours. Similar to the effect of launching a new tour from a 'particularly good projection' as described in Fig. 16 p.217 [^3].
        - Comparing the local optimal projections of starting for pairwise combinations of PCs rather than random initial bases.
        - Hence additional plots and relevant info on PCs required.
        
* Use of principal components and PCs plot (or Use of the Fisher linear discriminant and LDA index plot):
    + First check the variables are on comparable scales, rescale to unit variance if needed (default).
    + When using PCs we are interested in comparing the standard deviations of the PCs. We expect the first PC to have the greatest sd and the variation to decrease for subsequent PCs, but the size of differences in variation is of interest (p.357) [^2].
    + The coefficients of each PC indicate which combinations of variables are being compared with each other (p.357 example of interpreting PCs for `crabs` data) [^2].
    + Tours compliment numerical algorithms that find 'interesting linear combinations of data. These linear combinations might be fed into a tour or re-created directly using manual manipulation, after which their neighborhoods can be explored to see whether some nearby projection is even more informative' (p.34) [^1].
    + 'The first few principal components are often useful to reveal structure in the data' (p.331). [^2] So we only need to explore pairwise combinations of the first few PCs as starting bases for guided tours (?) BUT we still need to p number of PCs for the tour in order to explore the p-dimnesional data space (NB: p = # of X-vars). ie. Want k=p (see below about k)
    + PC are rotations of the original variables that best explain the variation in the data. If we only take the first k principal components then 'the subspace they span contains the best k-dimensional view of the data'. Since the covariance matrix is maximised and the residual sum of squares between the original points and their projections is minimised (p331) [^2]
        - To do: Double-check understanding of biplots as when k=2 (scatterplots with PC1 and PC2), so biplots are best 2D view of the data. Specific static projections of 2D tours are equivalent to biplots with axes rescaled to equal length (see p.35). [^1]

## animint (R package)
See: <https://github.com/tdhock/animint>
* "Academic paper" found from link above looks like a draft of the draft from Paul.
See: <https://tdhock.github.io/animint/#introduction> (not that useful)
* Han's Rosling's World Bank example: <https://cpsievert.shinyapps.io/animintRmarkdown/> (not that useful)
Code: <https://github.com/tdhock/animint/tree/master/inst/examples/rmarkdown>
* Can brush aggregate plots.
* Can brush pcp (timeseries).
    + Also demonstrated by Sievert in his draft paper using plotly.
* dev version only.
```{r, eval=FALSE, echo=TRUE}
# Install dev version of animint package
devtools::install_github("tdhock/animint", upgrade_dependencies=FALSE)
```


## tourr (R package)
* See: <https://www.jstatsoft.org/article/view/v040i02/v40i02.pdf> [^4]
* Double arrow operator (<<-) allows assignmnet to parent levels (outside of current function or enviroment). The usual single arrow operator (<-) only allows assignment to current level.

### Tours
1. Sphere data (transform to principal components)
    + `sphere=T` (and `rescale=T` default) arguments rescales the data (to range [0,1]) THEN spheres it. Order matters.  The resulting PCs identifies more group structure than only sphere-ing. Better for `holes` pp but not much difference for `cmass`.
    + Use of PC's (rather than raw data Xs) chooses a starting point for the (random) tour path that is more likley to lead to interesting views. This results in more consistency between the random tours and increases the chance for the most interesting views to be consistently captured in each random tour.
    + PCA (Principal Component Analysis): Seeks to find a linear combinaton of X with maximal (or minimal) variance. The ith principal component is the ith linear combination picked that maximises variance and is uncorrelated with the linear combinations that have been picked earlier. ("The first few PCs are often useful to reveal structure in data")
    + Sphering rotates and scales data to remove 'typically obvious correlation' (p.8)
    + After sphering the data matrix will have a mean vector of zero and variance-covariance as the identity matrix.
2. Choose the guided (projection pursuit) tour.
    + In either 1D, 2D or k-D projection (hence choose a display method)
3. Choose a projection pursuit index (function to optimise).
    + Holes (`holes`), central mass (`cmass`), LDA (`lda_pp`) or PDA (`pda_pp`).
    + `cmass` = 1 - `holes` index
    
* 5 types of tour generators: Everything available in `ggobi` is available in `tourr`, with the addition of being able to "replay" a saved tour (`planned_tour()`)
    1. grand_tour
    2. guided_tour: projection pursuit with 4 indices
        - Holes (`holes`): few points in the center
        - Central mass (`cmass`): lots of points in center
        - Linear discriminant analysis, LDA (`lda_pp`): maximised when the centres of pre-defined groups are furtherest apart. Equal variance of groups assumption.
        - PDA (`pda_pp`): for small n, large p (`ggobi` has PCA in 1D as the fourth index option).
    3. planned_tour
    4. dependence_tour
    5. local_tour: alternates between specified starting position and nearby random projections.
    
* Replicate tour function and show trace of the tour paths to display the consistency of the endpoints of the random tours. Also the differences in tour paths when the orthogonal projecton of a different pair of PCs are used as the starting basis.
    + Visualising the path of a tour requires the use of multidimensional scaling of "principal angles" between planes. When represented on a 2D plot it does NOT represent the path's coverage of the X's-dimensional space, hence is not very useful for illustrating the consistency of tours. (See `visualise_paths.R`)

* Multiple display methods depending on projection dimension. Function: `animate(display="")` or `animate_*()`.
    + 1D: 
        - `dist`: histogram, ASH, density plot
        - `image`: image plot
        - `ts`: time series
    + 2D:
        - `xy`: scatterplot (biplot?)
    + 3D:
        - `stereo`: anaglyphs (require 3D blue-red glasses to view)
        - `depth`: 3D depth cues (using size, colour,...)
    + k-D:
        - `andrews`: Andrews curves
        - `faces`: Chernoff faces (not implemented in `ggobi`)
        - `stars`: star glyphs (not implemented in `ggobi`)
        - `pcp`: **parallel coord plots**
        - `scatmat`: **scatterplot matrix**
    + Arguments
        - `fps`: frames per second, controls smoothness of transition between frames.
        - `aps`: angular velocity, speed of tour along tour path.
* "very easy to hook up to additional method of data display" that is already available in R.
* `tourr` functions are sensitive to the order of vars in the dataframe used since the default 'start' projection basis is the orthogonal projection of the first two variables.

## Tableau
* See: <http://onlinehelp.tableau.com/current/pro/desktop/en-us/actions.html>
* Tableau interactive visualisation can be shared via it's web application framework ('Tableau Public` <https://public.tableau.com/s/>)
* `URL Action` (hyperlink w results from other actions) is an additional technique that other tools may not have.
### Tableau Public (Free App version)
* Drag and drop to create plot.
    + Certain plot choices are available depending on type of vars selected.
* Create a `dashboard` to display plots side-by-side (for brushed linking etc)
* Create a `story` seems to be like a slide show.
### Interactive techniques ("Actions" in Tableau)

```{r table1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
tabl <- "
| Technique | Tableau |
|-----------|-------------------------------------------------------------|
| Identification | Y |
| Scaling | Y (zoom, pan) |
| Subset selection | Y (Filter action) |
| Drag points |  |
| Brushing | Y (Highlight action) |
| Linking |Y (between mutliple views within a dashboard) |
| Specify URL | Insert hyperlinks with interactive results in parts of the url address (URL action)<br>eg. Filter result as the search keyword for a website |
"
cat(tabl)
```

## Alteryx
* See <https://community.alteryx.com/t5/Analytics-Blog/Interactive-Visualizations-for-Predictive-Analytics-with-Alteryx/ba-p/3605>
* Drag-and-drop interface
* Difficult to share with non-Alteryx users: 
    + The examples on the internet are all static images or videos, viewer can't "play" with the interactive visualisation without having the Alteryx software
* Connect with `Tableau`.
* "Added interactive dashboard outputs" to specific `Predictive Analytics` tools. 
    + Each interactive dashboard is different depending on the tool at hand.
        - Seems like the interactive techniques are designed very specifically for the specific type of "predictive analysis" tool.
        - So an interactive technique that is possible in one dashboard may not be available in another dashboard.
     + The 9.5 version focused on 4 dashboards: <https://www.slideshare.net/Alteryx/inspire-2015-interactive-visualizations>
    + The 10.0 version focused on the dashboards of the following:
        - `Field Summary` tool
        - `Time Series` tool
        - `Network Analysis` tool
    + The latest version 11.0 doesn't seem to have any additional interactivity, but otherwise they seem to be adding techniques on as they see the need arise.

### Interactive techniques (for dashboards of specific "tools" in Alteryx)

```{r table2, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
tabl <- "
| Technique | Alteryx |
|-----------|-------------------------------------------------------------|
| Identification | Y |
| Scaling | Y (eg. Time Series tool)|
| Subset selection | Y (filter and sort)|
| Drag points | Y (Network Analysis tool) |
| Brushing | Y |
| Linking |Y (between mutliple views within a dashboard) |
"
cat(tabl)
```

## ggobi/rggobi
* See <http://www.ggobi.org/docs/>
    + Teaching ideas (stats concepts linked w demo of how ggobi can be used to explore, reinforce those concepts). Lots of good ideas but need to pick which to focus on.
    + Datasets and code from Cook & Swayne book.
    + Bibtex references for ggobi readings 
* ggobi may set the benchmark of interactive techniques possible and help identify gaps.
* Developments to connect with R seem to be active (blog up to 2010). Recently?

### rggobi
* Code of basics in `rGGobi_intro.R` (following the `introductionRGGobi.pdf` from website)
* Transfering data between R and ggobi.
    + `ggobi()` function: 
        - Initiates ggobi in R, by transfering R data to ggobi 
        - Creates a `GGobiData` object
    + In R can retrieve `GGobiData` objects that are linked to GGobi 
    + 'ggobi_find_file()` function: (??)
        - Initiates ggobi in R, by accessing ggobi's "data" library
        - Tried: ggobi(ggobi_find_file("data", "olives.csv")) 
        - Returns blank ggobi control window
* Control ggobi displays/interactions from R using commands. (TBC)
    + `display()` function:
        - Inputs: `GGobiData`, "Name of plot"
    + `variables()` function: Two forms
        1. Returns the ggobi X, Y, Z values of its argument, the `display()`.
        2. Sets the attribute: `variables() <-` allows you to assign values to control interaction via R commands. 
* Recording interactions in ggobi (and transfering record to R). (TBC)
    + ggobi allows interactions to be recorded (independent of R) and exported as movie clips (see Disadvantages)
    + `ggobi_display_save_picture()` captures ggobi display as a raster image on file.
    + `DescribeDisplay` ggobi plugin and R package (TBC)
        - See <http://www.ggobi.org/describe-display/>
        - Create "R versions" of ggobi plots
        - Need to save to file in ggobi first and then load into R 
        - Can re-create using either plot() or ggplot()
* Recording dynamic analysis such as tours.
    + Sievert (Journal paper draft) uses `vimeo` with no voice over.
    + Hadley et al. ("...blindfold" paper on `tourr` package) embeds short bites of tours in the pdf document so that the reader can click and view without leaving the pdf document.  
        - Used `render()` in `tourr` package to save plots as pdf's and then 'glued' the plots together using the `animate` package in Latex.
        - Should be able to achieve similar with Rmarkdown (html) and `shiny`
    + Check if `screencast` or something similar will work in VM.
    

```{r, eval=FALSE}
library(rggobi)
# Transfering data between R and ggobi.
## Initiates ggobi and transfers mtcars data set from R
g <- ggobi(mtcars)
# Get this data back to R (either will work)
g[[1]]
g[["mtcars"]]

# Control GGobi displays/interactions from R using commands.
# Parallel coordinate plots  ----------------------------------------------------------
d <- display(g[1], "Parallel Coordinates Display")
# Interaction: subsets and re-orders the variables on the axes of plot 
# Will order subset of vars in ascending number order 
d <- display(g[1], "Parallel Coordinates Display") #Displays all vars
variables(d) 
variables(d) <- list(X=c(2, 8, 1)) # Displays mpg(1), cyl(2), vs(8)
# Wanted: cyl(2), vs(8), mpg(1)
# To try:
variables(d) <- list(X=c("mpg", "cyl", "vs"))

# The order in which you call up the variables() <- assignments results in different orderings of the axes
# Sometimes order of (X=#:#) matters 
d <- display(g[1], "Parallel Coordinates Display")
variables(d)
variables(d) <- list(X=8:6) # Subset: Displays wt(6), qsec(7), vs(8)
variables(d) <- list(X=8:1) # Reorders
# If use (X=1:8) above, the final result is 6, 7, 8, 1, 2, 3, .., 5.
variables(d) # Displays wt(6), qsec(7), vs(8), then drat(5), vs(4), .., mpg(1)
```

#### Thoughts in progress (on rggobi)
* Focus on: *Recording interactions in ggobi (and transfering record to R)*, rather than, *Control ggobi displays/interactions* 
    + Parallel coordinate plots interaction seems un-intuitive. Re-ordering of axes is possible but tricky since order defaults to ascending the numeric value the var is associated with.
        - Check if calling by var name works. 
    + The `introductionRGGobi.pdf` suggests this area could be limited:
        - "Modifying observation-level attributes, or automatic
brushing." and "Basic plot control"
        - BUT this document could be dated.
    + Regardless may be good to focus on how to get a "code record" of interaction via ggobi GUI out, rather than focus on controlling interaction via R commands?
        - This would allow us to build on TOP of the teaching ideas offered by ggobi, rather than just write code to replicate the interactions.
        - Instead focus on processing the "code record" of interaction that we would get from ggobi and how to analyse that further in R or present it with Shiny and/or other interactive tools.

### ggobi
* Interaction choices vary according to the type of plot in the active view (eg. the plot you want to brush on)
    + All have at least: scale, brush, identify
    + Identify: 
        - Either by hover or display info in console 
        - Can display any variable value (even those not in plot)
    + Scatterplots have more interaction options: 
        - Edit edges: add points or edges
        - Move points
        - Cycling of pairwise combos for scatterplot axes
    + Scatter matrix can brush, scale and identify, linking within itself and to other views too
    + Bar charts: 
        - Responds to brushing in other plots by highlighting the proportion brushed (or a highlighted line appears if only one obs brushed)
        - More than one bar can be brushed (when initiating interaction from the bar chart)
* Similarly plot display options vary depending on type of plot
    + Parallel coords plot: 
        - Advanced options (eg. using ASH)
        - Easily drag to change order of axes
        - Brush node to select (or edge)
        - BUT cannot do some Mondrian interactions (see disadvantages) 

#### Advantages
* Very fast and flexible
    + Can have multiple plots linked at once
    + Brushing takes effect immediately using the olive.csv (around 572 obs)
* Lots of options for interaction and plot display
* A rich resource for teaching ideas (see website link)
* A wide range of in-house interactions (ie. it is a complete pipeline and does not need add-ons to achieve the interactive techniques). 
* Some statistical analyses available that can be applied directly to interaction.
* Currently, probably the best interactive tool for handling large ds.
* Able to brush, link and identify when using parallel coordinate plots BUT difficult to isolate individual cases if there are many similar cases close together (check brushing ease of brushing edges again)

#### Disadvantages
* Open source but difficult to install due to specific software requirements.
    + Ease of installing software (X11 problem on macs only?)
* Very specialised, only useful if you know what you are doing!
* Easy to publish? Export options? Sharing options?
    + Movie clips seem to be one of the main ways of documenting visual interactions in ggobi (see website demos). Raster images, pre-recordered, cannot be interactive "again" during presentation.
* Parallel coord plots: 
    + Cannot change axes scaling (eg. use global max min for scaling, or align to median)

## Shiny
* http://shiny.rstudio.com/reference/shiny/latest/
* reactive({}) ‘reactive conductors’ (See: http://rstudio.github.io/shiny/tutorial/#reactivity-overview)
    + reactive conductors sit between reactivity source(s) and endpoints (eg. between a sliderInput and the plotOutputs it updates). This allows any objects defined by reactive({}) to be called as a function in the code for the output plots.
    + reactive({}) has the same effect as defining the object as a function (and calling it up as a function in the code for output plots).
    + Shiny+Plotly: Using function(){} rather than reactive({}) seems to be better if the object is defined by complicated computations of inputs. Using reactive({}) seems to slow down the tooltip and plotly_click reactivity. (See poisdp.R but need further investigation)
* plotOutput() interactivity arguments in ui code:
    + https://shiny.rstudio.com/articles/plot-interaction.html
    + Four interaction arguments: click = "plot_click", dblclick = "plot_dblclick", hover = "plot_hover", brush = "plot_brush".
    + "Results" of interaction are displayed off-plot in text form in the examples on the website, but doesn't have to be?
    + Might not be useful since needs to link up with nearPoints() and brushedPoints() functions in server code which all use pixel approximations (see Disadvantages below)

### Interactive environments in Shiny
* Possible use: Documenting interaction back to R
* `eventReactive()` in Shiny with a `actionButton`?
* Tips: Double arrow assignment allows you to assign value to a global variable from within a 'local' environment
    + eg. posterior.global <<- a (where a is a value from within ONE of the output chunks in the server code for the Shiny app)
* `isolate()` useful in a reactive environment when you want certain vars to remain the same (unaffected by interaction)
* Possible differences between `eventReactive()` and `observeEvent()` (used below):
    - `eventReactive()` delays code running while `observeEvent()`'s code in second argument is triggered straight away by the `input$___` (first arg).
    - Hence `eventReactive()` can be assigned as a var and executed in another chunk of server output code (ie. it becomes a "reactive expression"/global variable)
```{r, eval=FALSE}
# You can define a plotly_click event as a reactive expression and then use s() and a() to create (multiple) Shiny outputs
  s <- reactive({event_data("plotly_click", source = "obs")})
  a <- reactive({poisdp(s()$x, mu(), prior(), plot = FALSE)})
  
# Updates with a Shiny button
## ui
# Button to submit posterior as the "new" prior distn
actionButton("new", "Update posterior as prior")

## server
prior <- reactiveValues() # set by user input initially, then it will be updated by posterior.
  posterior.global <- reactiveValues() # to keep the posterior values for the next round.
  newButton.reactive <- reactiveValues() # to redraw heatmap by pressing button 

# Uses the initial prior (from the user input text box) if the "update button" has not been used
if(is.null(posterior.global$posterior)) {
          prior$obj <- as.numeric(unlist(strsplit(input$prior, ",")))
}
  
# Using a ______$___ creates a var to attach to a reactiveValues() object. 
observeEvent(input$new, {
      if(!is.null(posterior.global$posterior)) {
          prior$obj <- posterior.global$posterior # update prior (reactive variable) with posterior values in the previouse round.
          newButton.reactive$obj <- Sys.time() # Once newButton.reactive values is updated, it will draw heatmap again.    
      } else {
          # Do nothing
      }
  })

```


### Advantages
1. Talks back to R.
2. Easy to learn and set up. Good online tutorials.
3. Aesthetically appealing output (publish-ready).
4. It is possible to make any bitmap/raster image interactive using nearPoints() etc, but user will need to transform pixel units to something useful in the data. (This is done for you when the bitmap images are from R base plots or ggplot2). See: https://shiny.rstudio.com/articles/plot-interaction-advanced.html

### Disadvantages
1. Needs to be combined with another package in order to achieve the 'classical' interaction techniques described by Cook and Swayne. In order to make the plot region interactive.
2. Encounters problems for plots with a large data file? (AQ flights parallel coordinate plot will no upload on Shiny server *Error: 'AQ' object not found*. Similarly when used in RMarkdown. See: Shiny -> Subset_radiobutton.R and MidSem1Report.Rmd).
3. Good for "off-plot" interactions but not "on-plot" (see below).
4. nearPoints() and brushedPoints() uses a mapping from the pixels of the raster/bitmap R plots from base R or ggplot2, to observation numbers in the data frame to link the brushing.  This will be ineffective (impossible?) for large data sets due to over-plotting. Seems inefficient compared to interacting ‘directly’ with a SVG.
    + See: https://shiny.rstudio.com/articles/selecting-rows-of-data.html
    + nearPoints() and brushedPoints() has a default of capturing within 5 pixels of the mouse event, but can change to be more or less.
    + nearPoints() and brushedPoints() are really the same.
    + Can brush on facet plots in ggplot2.
5. Cannot use R Console when running a Shiny app.

## Plotly
* Code for yet to be published journal paper:
<https://github.com/cpsievert/pedestrians/tree/master/docs>
* 2017 Webinar: <https://plotcon17.cpsievert.me/webinar/#1>
    + Brushed linking examples (without use of `Shiny`)
    + `SharedData` and `highlight()` (with `crosstalk`)
* https://plot.ly/r/reference/
* Book (Phd thesis?) by author of plotly: https://cpsievert.github.io/plotly_book/
* Create interactive plots using either: plot_ly() or ggplot2 %>% ggplotly().
* plot_ly() uses ~ before variable names. Otherwise similar to ggplot2: 
    + 'ggplot() + geom_*()' = 'plot_ly() %>% add_*()'
* ggplotly() translates each layer of ggplot2 into one or more plotly.js traces. Assumptions about trace attributes not always appropriate, can modify. See: <https://cpsievert.github.io/plotly_book/extending-ggplotly.html> (Extending ggplotly).
* plot_ly() interacts more directly with plotly.js and hence generally not as ‘expensive’ as ggplotly(). Maybe faster with large ds?
* Tooltip identification can be customised:
    + ggplot(aes(label=colName, label2=colName1))
    + ggplotly(tooltip = "label", "label1")
  
### Advantages
1. Easy to convert ggplot2 plots (including plots from `GGally` package) into plotly objects using ggplotly().
    + With ggplot2 brings the flexibility of creating a wide range of plots. plot_ly() not as extensive in graphics, but interacts more directly with plotly's javascript library.
2. Aesthetically appealing output (publish-ready).
3. Defaults: Tooltip identification of aesthetics, scaling.
4. Persistent brushing easily achieved by an argument: pipe plotly object to a ‘highlight()’ layer with ‘persistent=F/T’ and ‘dynamic=F/T’ arguments. Limitations to ‘memorising selections’ and currently a limited number of modes to choose from (cannot support AND), rewinding selections? (See Hofmann and Theus (1998))
5. plotly objects can have more than aes mapping data attached to them, such as statistical output that was generated in R by ggplot2 when creating the plot. Eg. with goem_smooth() See: https://cpsievert.github.io/plotly_book/extending-ggplotly.html (Extending ggplotly)
6. Can still use R console when interacting with the plot (if using `plotly`+`crosstalk`).
7. Discussion on use with `shiny` and/or `crosstalk`:
<https://community.plot.ly/t/plotly-crosstalk-issue/3810/2>
    + "The goal is to produce standalone html" (Sievert, 2017 webinar)

### Disadvantages
1. Does NOT talk back to R: cannot re-execute statistical procedures in response to user event since can’t talk back to R (currently loses the inverse function required to get from the graphic back to the data object when the results are pushed to a web browser). 
2. When data points > 50 000 (eg. AQ delay data):
    + Delay in creating ‘zoom in’ default scaling of plot.
    + Difficulty keeping up with tooltip display.
    + Lasso/click drag selection very slow and hard to control, difficult to use for exploration.
4. Tooltip identification for area plots (bar charts) a bit hit and miss? Esp with ggplot2 plots? Does not take all categorical labels with it when passed thru ggplotly()?
5. Cannot brush (select) edges or nodes of parallel plots.
    + Can "click" on nodes but only records one observation

## Crosstalk (htmlwidgets, highchartr?)
* https://rstudio.github.io/crosstalk/using.html
* Crosstalk creates a ShareData environment for inter-widgets communication.
* Can still use R console during interaction? YES, it appears so with `plotly`.
* htmlwidgets for 3D rotation (and more dimensions?): https://www.r-bloggers.com/a-first-look-at-htmlwidgets/
* `SharedData` environment
    + Each `SharedData$new(... group="..")` call makes a new `group` of widgets that link to each other.

### Advantages
1. Talks back to R.
2. Purely Javascript, so easy to embed in web pages.
3. Achieves similar linked brushing as Plotly by creating a common data set automatically (via ShareData) rather than the user having to manually subset (as with Plotly).
4. The Methods in the documentation of ShareData suggests it captures more info than event_data() in Plotly+Shiny.
5. Much easier to link plots ‘both ways’. Also possible in Plotly but requires more code. Crosstalk seems to be created specifically for linked brushing, while Plotly more generally for identification (that can then be manipulated for linked brushing).
6. There are html widgets which are ‘Shiny-like’ filter inputs that can work in static HTML documents, like Rmarkdown (eg. htmlwidgets frame is like a Shiny sliderInput).
7. Has the potential to connect with html widgets of your own choice, but currently has specific requirements in terms of which htmlwidgets Crosstalk is appropriate for.
8. Allows linked views between two independent graphing systems (eg. plotly and leaflet maps)

### Disadvantages
1. Not appropriate for large datasets. Serious delay in interactivity when only around 5000 points are displayed (see Example 3 in MidSem1Report).
2. Only appropriate for html widgets where obs are represented individually (ie. not appropriate for aggregate plots).
    + Not appropriate for aggregates since cannot ‘dim’ unselected values in a box plot, but with (plotly+shiny) can re-draw with selected points.
3. No equivalent “plotly_click” type of interaction.  Not necessary for scatterplots since can brush just one point, but this may limit Crosstalk interactions (e.g. not possible to create the Plotly correlation heat map type of interaction, https://plot.ly/r/shinyapp-linked-click/).

## Shiny + Crosstalk
* https://beta.rstudioconnect.com/jcheng/shiny-crosstalk/

## Plotly + Crosstalk
* Can talk back to R? (Crosstalk can but Plotly can't)

### Advantages
1. Can still use R console when interacting with the plots.

### Disadvantages
1. Not appropriate for large ds (see Crosstalk)

## Plotly + Shiny
* https://plot.ly/r/shiny-gallery/
* Uses event_data() to capture 'event' of interactivity.
    + event = 'plotly_click' and 'plotly_selected' are useful of the 4 possibilities.
    + ‘plotly_hover’ and ‘plotly_relayout’ do not provide meaningful interactions. (Output for plotly_relayout is x and y window dimensions of zoom).
* layout(dragmode="select") useful if want to default to brushing when drag to select (rather than scaling)

### Area plots: ggplot2 + Plotly + Shiny
* Linked brushing via click on mosaic plot works (see Brush_mosaic.R in Shiny_Plotly folder).
    + VERY slow due to 50 000+ points in scatterplot
    + Use a highlighted bar instead, or something more appropriate for categorical data
    + See: 
* Using ggplot2 + geom_bar(): Assign the fill=probability and col="y factor level" and then use scale_color_discrete(low="black", high="black"). This means the y-variable will also appear in the tooltips.
* productplots package 
    + The best option so far (see code below, from AreaPlots.R)
* ggmosaic package (an add-on to ggplot2) allows you to add a geom_mosaic. 
    + See: https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html
    + Comment at bottom of page on using geom_mosaic with Plotly has been masked
    + It uses the  productplot package but seems to disable the productplot package with errors (resolved by installing productplot from CRAN again). The version of productplot used in ggmosaic outdated?
    + Currently cannot get ggmosaic working

### Advantages
1. plotly_click allows for aggregate brushing for discrete vars. BUT can be extended to aggregate plots of real-valued variables? (eg. histograms, hexbins?)
    + Compare Brush_histogram.R and Brush_bar.R (works fine).
    + geom_hexbin:
        - 'plotly_selected' records nothing, returns empty list.
        - ‘plotly_click’ records ‘curveNumber'=rank of frequency (ie. all bins with count=1 has curveNumber=0). This could not be used to group data as it may be possible with using plotly_click with a histogram (see below).
    + geom_histogram:
        - might be possible to use 'plotly_click' but need to see how to access the bins that are 'imported' into plotly.
        - Brush_histogram.R: The highest frequency (count=11302) bin has curveNumber=75. All the bins with frequency = 1 has curveNumber=0.

### Disadvantages
1. Linked plots can only use variables that were in previous plots or called on by Shiny inputs (unable to use a diff var for colour in output plot of Brush_input).
2. Brushed linking possible, but requires more code to set up than using Plotly+Crosstalk. Especially "two-way brushing" (ie. brushing from any plot). Defaults to rescaling plot according to selection. 
3. event_data() is limited in the 'details' it captures from each event (x, y, curveNumber, pointNumber)
4. Need the 'details' from the event differently depending on the type of plot that the interaction was initiated in. Eg. For scatterplots pointNumber=(obs#-1) offset by 1 due to different languages being used. For brushing on a bar chart 'x' can be directly used to subset and identify selection in df.
5. Brush and link does not work for large data sets. Not all members of the brushed subset are plotted on the linked plot.  Number of obs plotted seems fewer than those showing in the R output for the subset.  See: Brush_Link_large.R 

## Shiny + Crosstalk + Plotly (?)
* If using Crosstalk w ggplot2 in Shiny, then need Plotly, since ggplot2 plots are not htmlwidgets?
* SharedData environment needs to be activated in R before launching Shiny app. See: 
https://github.com/ropensci/plotly/blob/51e159ba825b007657c1d7534825ef25afc7e7af/demo/shiny/basic/app.R

## trelliscopejs
* See <https://hafen.github.io/trelliscopejs/#why>
* `Trelliscope` (the predecessor of `trelliscopejs`) was focused on catering for large ds and it was built on a different platform (and not a JavaScript library like `trelliscopejs`).
    + `trelliscopejs` currently not catering for very large ds.
* `trelliscopejs` talks back to R? 
    + Yes, one of the aims is for the user to be able to record their interaction for sharing.
    + See *Viewer improvements...* in <https://hafen.github.io/trelliscopejs/#upcoming-work>
    + BUT I can still use R console while interacting with `trelliscopejs` in both the viewer AND the pop-out Viewer Zoom window in RStudio.
* `trelliscopejs` is like trellis plots with the added interactivity of being able to filter and sort panels of multiple trellis plots based on "cognostic" summaries of the data.
    + "cognostic" = diagnostics guided by computers (term proposed by Tukey)
    + Cognostics in `trelliscopejs`: Statistical summaries automatically calculated for the subsets that are created by interactive filtering.
    + Defualt cognostics automatically calculated by `trelliscopejs`:
        - Mean for all numeric vars (whether used is current aes or not)
        - Value of the categorical vars used in the subsetting/ the "conditioning variables" (will not display the values for other categorical vars that were not used to subset the data and 'trellis' the plots, this would require something like a list of counts)
    + Customised cognostics possible: eg.
* `trelliscopejs` produces *small multiple plots which can be navigated with respect to the summaries*
* Interactive options on sidebar:
    + `Grid`: # rows and cols of plots for each panel, and order by row or col.
    + `Labels`: The cognistic summaries to display below each plot (ie. mean for the subset across all the numeric vars in ds, count for subset and categorical values defining the subset)
    + `Filter`: Selection plots to view based on cognistics (same list as in Labels)
    + `Sort`: Ordering of plots based on values of cognistics.
* Low level functions: 
    + `facet_trelliscope()`: Use in place of `facet_wrap()` in `ggplot2` (turns it into a interactive faceted plot rather than a static one)
        - `path` arguments sets the directory where you want the displays to be saved and accessed for viewing
    + `trelliscope()`: Use when you want to customise cognostics (ie. calculate and display summary stats other than the defaults calculated by `facet_trelliscope()`) 
        - Use with a "tidy" workflow: group data for computing summaries for each group (using `dplyr` or `tidyr`) and then use `trelliscope()` to display the summary stats alongside (below) the plots of the subsets
* `trelliscopejs` is an `htmlwidget` interface to the JavaScript library by the same name (`trelliscopejs-lib` - allows for the interactive viewing). 

### trelliscopejs and `rbokeh`: 
* See <https://hafen.github.io/trelliscopejs/#getting-started>
* `figure()` is the equivalent of `ggplot()` in `rbokeh`.
* `ly_points()` has `hover=` argument.
* `rbokeh` similar to `plotly`? YES
    + `rbokeh` requires more code to display hover tips
    + `rbokeh` + `trelliscopejs` has explicit examples, not so with `plotly` (currently I cannot get working)
* Can use `plotly` instead of `rbokeh`?
* `rbokeh` less "integrated" to R/Shiny than `plotly` currently is (Shiny interactive functions for `plotly`, like `event_data()`).
* `bokeh` is popular with Python users (Yu Han).
    
### trelliscopejs and `plotly`
* See <https://plot.ly/r/shinyapp-explore-diamonds/>
* Currently using plotly it's plotting all of the data in each plot, rather than the subset.  See `trelliscope_example.R`.

### Advantages
* Intended for exploratory data analysis (easy, quick) and in some ways for presentation/communication of exploration to others (see next point)
* R Console still works while interacting in the RStudio Viewer panel and the pop-out Viewer Zoom window (with different interactions)
* Easy to understand for "non-data-scientists" or domain experts
    + A communication tool between data scientists and their audience or those they collaborate with.
* Exemplifies *small multiples* as an interactive technique:
    + breaking up the dataset into multiple plots of the subsets - what a trellis plot achieves.
    + small multiples = *where data are split into groups and a plot is made for each group, with the resulting plots arranged in a grid.*
    + Easy and quick to create small multiple plots, hence well suited for EDA where some may be dead ends and want to reiterate rapidly.
    + Tufte, *Visual Display of Quantitative Info*: Understanding how to read one *slice* allows the user to access all of the data via the other slices. *Allows viewer to focus on changes in the data rather than changes in the graphical design*.
    + Slicing data to allow for multiple views is useful when there are many vars involved.
        - Uses one or more vars to determine how to splice up data.
        - For each subset plot the data using one or two vars.
        - More effective than 3D visualisation and can scale up higher than 3D.
    + Resolves problems w overplotting and allows detailed views.
    + Scalable since does not require all points to be plotted in one view.
        - The "cognostic" panels guide the user to the panels w the "most interesting content"
* The *input combinations represented as cognostics* allows for many outcomes to be compared simultaneously.
    + As opposed to apps that allows a few inputs and then the plot updates.
* Easy to use with `ggplot2` and `lattice`. 
    + `rbokeh` recommended rather than `ggplot2` since its faster at drawing panels of plots. See <https://hafen.github.io/trelliscopejs/#gapminder_data> 
* Combinations for how the dataset can be subsetted are easily generated in `trelliscopejs`.
* `trelliscopejs` graphics can be shared as standalone apps or embedded in RMarkdown notebooks.
    + For use in RMarkdown: Must set argument `self_contained=TRUE` (in either `facet_trelliscope()` or `trelliscope()` function).
        - This loads all of the plot dependencies onto the html page instead of saving in separate files for access as they are viewed. Do NOT set as TRUE otherwise, since this is esp expensive when there are many panels and hence is more efficient to load on demand rather than all at the beginning.
        
### Disadvantages
* See Hafen's "to do's" for `trelliscopejs` <https://hafen.github.io/trelliscopejs/#upcoming-work>
* Underdevelopment still (not so much stackexchange 'help' out there)
* Specific to *small multiples* interaction (filtering and sorting of trellis plots). Uses linked brushing when filtering by a continous var. Limited in scope of interaction or user customisation opportunities. Cannot really 'get under the hood'.
* Will take a while to load all panels for large ds.
    + Focus of `trelliscope` was for use w large ds.
    + Initial/current focus of `trelliscopejs` is on the interface 
* Aware of the usefulness of being able to record interaction (see link above on 'upcoming work')
    + *We would also like to make the viewer be able to track and share state*
* The target users of `trelliscopejs` may be limited (landing in between those who want to code and those who don't). `trelliscopejs` may be more like the user interfaces provided by commercial software like `Tableau` but on a much smaller scale (and hence not able to compete)
    + It provides a very user-friendly user interface but leaves little room for the user to modify, customise or design their own user interface. This may not appeal to users who can code. 
    + `Shiny` on the other hand provides the flexibility for customisation of the interaction interface to whatever extent the user's coding skills allows.
    + The user-friendly interface appeals to users who do not want to code or have limited coding skills, but they may be unmotivated to learn the minimal amount of coding that is necessary to use `trelliscopejs` for just one specific interaction technique (*small multiples*). Especially if there are more comprehensive (commercial) ready-to-use interaction interfaces available, like `Tableau`.

## ggvis 
* http://ggvis.rstudio.com/ggvis-basics.html
* R package that is ike a combination of Shiny and Plotly, under development, likely to change quite a bit.
* Has a similar layer ggplot2/plotly approach to plotting with ~ before vars and piping %>%.
* Comments on tooltip here are useful: https://github.com/rstudio/ggvis/blob/master/R/interact_tooltip.R
    + Tooltip identification allows only ONE aes to be identified
    + Like plotly, only uses data columns used in the plot BUT can "use a key to line up the item from the plot with a row in the data".
    
### Disadvantages
* Cannot use R Console when interacting with a ggvis plot: "every interactive ggvis plot must be connected to a running R session"
* Likely to change.
* Tooltip identification only allows 1 var, but may be able to display a var that is not an aes from the plot (see above).

## R Base graphics
* Some interaction techniques are possible. See example from Paul (email attachment)

### Disadvantages
* Relatively slow at drawing graphics compared to a browser platform, but base plots will be faster at rendering plots in R than grid plots, like ggplot2 (see runtime.R).
* Possible, but difficult to locate interaction (ie. click location) since raster images are used.

## Large datasets
* Current interaction tools can help when there is a large number of variables, through filtering inputs, but when there is a large number of observations, problems with over plotting and time taken to create plots, get in the way of using these tools for meaningful interactions.
* Brushing or “click selecting” on plots using bins would be useful for large ds, since difficult to brush with over plotting.
* Unwin, 2015 "Graphical Data Analysis with R" (p.272):
    + Two problem areas for statistical analysis:
        - Large # vars = large # tests = more likely to get significant results
        - Large # cases = even small effects will be found to be significant in individual tests, but may not be of practical importance
    + *Large ds tend to be heterogenenous rather than homogeneous*
        - Select vars to create a subset of cases to use in the analysis.
    + The aggregate properties of the whole dataset will be reflected in a random sample. 
        - Perform statistical analysis on a sample, or repeat analysis on several samples.
        - Good for *global properties* of a dataset, but not good for local properties such as unusual small groups.
* Zooming in (w an un-zoomed view on the side, so contest is not lost) is esp useful for large ds.

## Tips
* Testing: Assign variable to interaction fn and print() the output.
* Colour #RRGGBB__: http://sape.inf.usi.ch/quick-reference/ggplot2/colour
* Brewer colour scheme: Qualitative, Sequential: Gradual distinctions (0 to 1), Diverging: Very obvious distinctions (-1, 0, 1)

### Virtual Machine
* Software to have on VM:
    + R (RStudio if possible?) with the following packages:
        - rggobi
        - DescribeDisplay
        - shiny
        - plotly (requires ggplot2)
        - crosstalk: devtools::install_github("rstudio/crosstalk")
        - iplots (?)
        - dplyr
        - tidyr
        - ggally (requires ggplot2)
    + ggobi
    + Mondrian
    + Manet
* Installation:
    + Download VirtualBox from <https://www.virtualbox.org/>
    + MAC: If stuck on verifying, see: <http://osxdaily.com/2016/07/26/fix-stuck-pkg-verifying-installer-mac-os-x/>
    + Transfer files from USB.
    + BEFORE starting a session in VirtualBox change the "Shared Folder" directory to where you saved the USB files.
    + Start session in VirtualBox (search for Terminal etc)
    
* Using GIT with VM:
    + Setup (do only once) to pull, merge and commit to a subdirectory, see: <https://lakehanne.github.io/git-sparse-checkout> (typo in .git/info/sparse-checkout no speech mark at the end)
        - This fetches all files in remote repo but does not checkout all of them (ie. clone with a sparse checkout)
    + START of every work session: Check if you have the 'current' version from the remote (git) repo.
        - Command: git pull origin master
        - gitGUI: Sync button
    + END of every work session: Commit any changes
        - Command: git status (Clean?)
        - If not git add ., git commit -m "...", git push.
        - gitGUI: Commit & Sync button
* ggobi/rggobi
    + ggobi control window is on the Terminal option menu (rather than a separate window)
    + `DescribeDisplay` ggobi plugin is installed but R package yet to be installed.

## General comments 
### The role of interactive visualisation
* Difficult to argue that the use of interactive data visualisation AlONE is sufficient for analysis. BUT graphics should be part of all analyses and INTERACTIVE techniques enable visuals to play an even greater role in revealing insights about data as well as evaluating and understanding results from numerical methods. Interactive visuals are not only useful for communication, but an essential part of any analysis, alongside numerical methods.
* Aim to make interactive graphical techniques easy to access and apply, to more data analysts, but still allow modification and generalisation.
    + `ggobi` is rigourous and easy to apply but access to the software is limited (due to installation requirements). Also no room for modification.
    + `R` is easy to access, use and allows for modification as well as generalisation.
    + Create a template for using tours for data analysis based on the techniques used by Cook and Swayne. Hopefully this allows relative novices to explore the techniques and develop an understanding of how tours can be applied to a range of problems.
        - A stepping stone towards developing intuition in applying the interactive techniques.
        - To try and reduce the learning curve (and/or investment in time and effort required for set up) that may be discouraging ppl from applying or including interactive graphical visualisation techniques in their data analysis.
* Lots of recent examples where interactive visualisation leverages the way we communicate findings and/or make data more accessible to others (see Shiny gallery, etc) BUT is it effective as a explorative tool? Does it have the rigor to be applied alongside theoretical analysis techniques? 
Does *interactivity* provide extra leverage that a static graphic cannot in EDA? Could this lead to more use of interactive visuals in 'theoretical' analysis?
* Would we one day have an interactive plot as part of the output of functions? (eg. Bayesian: Instead of a table of likelihoods and joint probs, have an interactive graphic with tooltip identification)
* When using interactive visualisation for exploration we need the interaction to be 'fast' to be useful, so need to be mindful of writing efficient code. (eg. Use of functions like `ifelse` rather than if and then loops).
* Using 'modern' visualisation tools like `shiny`/`crosstalk` and `plotly`, for GDA and analysis has the added advantage of being easy to share and document. Also allows for modification, extending and indvidualising to a particular dataset.
    + Software like `ggobi`(and most likely `mondrian` etc) are powerful but specialised. The user is confined to the pre-determined and fixed visual template of the environment. A template is helpful for guiding initial GDA but being able to extend and modify the template would leverage it.
    + Tours: Being able to 'rewind' and review the tour and capture interesting views. See `tourr` folder.
        - `plotly` allows for a static plot to be captured when interacting with the plot (in the "app").
* Need to be confident and familiar with the statistical processes represented by the visuals in order to interpret appropriately.
* Transfering visuals (interactive\dynamic or not) from one environment to another (eg. `ggobi` to `R`) generally results in modifications to the visual, which may lead to significant details being lost. Also the transferred object may require some work to make it compatible with other functions in the new environment.
    + Preferable to stay within `R` environment since there are lots of packages that can be used together.

#### Advantages (arguments for)
* Parallel plots largely unuseful without interactivity (see Unwin and/or Cook)
* Mosaic plots are much easier to understand with tooltip identification
    + Overcomes the labeling challenges of a static mosaic visual.
    + BUT nesting too many factors would still be difficult to interpret.
    + Shiny slider w 'level=1', 'level=2' for plots from `productplots` package would allow better understanding as well as exploration of low-dimensions first (as recommended by Cook etc) 
* Graphics is the only medium for communicating and interpreting results from 'flexible transformations' such as splines. (See 762 Handout 1, 'What is regrssion for?' and splines lab, Thomas Lumley).
    + With tooltip identification you can interpret the coefficient(s) of interest after applying a linear spline adjustment on the confounder.

#### Disadvantages (arguments against)
* Conclusion drawn from visualisations, interactive or static, seem objective (compared to the subjectivity of analytical and/or numeric output).
    + Different people will 'see' different patterns and hence draw different conclusions.
        - BUT the 'different conclusions' may be within the range of reasonable solutions (ie. not differ drastically, a bit like within a CI for point predictions from different samples of the same population)
    + Similar challenges to accepting conclusions from empirical data.
        - See Efron: 'resistance to empiricism' (in the context of bootstrap methods?)
* Novices may be afraid of making wrong decisions (eg. to sphere or not to sphere? Argument settings) and errorneous visual interpretations.
    + Decisions also need to be made when using numerical methods but numeric methods may seem more formulaic or can be 'taught' in a more formulaic manner. ie. You can follow a worked example to apply the numerical method and interpretation to a new problem. The yardstick used to make a judgement usually involve values that are fixed or comparisons between quantifiable magnitudes. 
    While graphical analysis may seem more intuitive and subjective, with the approach and interpretation dependent on the specific problem (?). Hence more effort, confidence and experience (?) is required when using visuals in data analysis.

#### Focus on making/finding examples that..
* Connect with statistical analysis or some part of EDA. For example:
    + Interactive graphics for examining missingness
* Bridge R/Shiny and "EDA/GDA-focused interactive software" to demonstrate how the transition from interactive graphics for exploratory analysis to presenting can be "effortless" and hence encourage ppl to use more interactive graphics in all stages of data analysis.
    + ie. Use the popularity of Shiny to encourage use of other interactive software, like `ggobi`.
    + `ggobi` and `rggobi` in `R` to `Shiny`: 
        - EDA in `ggobi`: Use grand 2D tour to identify views where clusters are most clearly defined.
        - Send these optimal views to `R` via `rggobi`
        - Re-create the principal component plots (?) in `R` to use in a `Shiny` app to PRESENT results of the grand tour.
        - NOT focus on trying to replicate a grand 2D tour in another tool (ie.`R` and/or `Shiny`).
        
### Indirect and direct manipulation
* NOT equivalent to off-plot and on-plot interaction! "Direct manipulation" is a compsci term, becareful how you use it.
    + on-plot: user interaction with the plot region (eg. brushing, hovering on a plot feature).
    + off-plot: user interaction with widgets that are not in the plot region (eg. Shiny inputs, htmlwidgets frames). (htmlwidgets will a mixture of on-plot and off-plot interactions)
* See *Linking views without Shiny* in:  https://cpsievert.github.io/plotly_book/linking-views-without-shiny.html
    + Indirect manipulation useful when the ‘unit(s) of interest’ cannot be easily located on the graphical space. 
    + Powerful to use both indirect and direct manipulation if they are synced. 
  eg. Select city from drop down menu to highlight plot (indirect) AND click on plot to have city appear in selection box (direct).
  
### Low-level and high-level programming:
    - low-level: harder to do since the language is 'closer' to the computer's 'native' language.
    - high-level: easier for the common user since the functions or commands will be 'translated' by intermediateries to the language that directly giving instructions to the computer.
    - eg. ggobi has a complex 'native' programming language, through rggobi, R provides a high-level programming language for more users to access the capabilities of ggobi. (Using ggobi via it's GUI does not require programming but you would be using it as a standalone)

### (Plotly+Shiny) vs (Plotly+Crosstalk)
* Linking requires either (plotly+shiny) or (plotly+crosstalk).
    + (plotly+shiny) re-draws whole plot after selection, inefficient if large ds or many graphical elements. eg. For brushed linking of scatterplots the full plot is re-drawn and then the layer for the selected points (in a different colour).
    + (plotly+crosstalk) changes the colour attributes of the selected points (dims unselected). 
* Large ds interaction (plotly+crosstalk) feels even slower than (plotly+shiny). Slowed down by crosstalk (?) which is self-claimed to be inappropriate for large DS. Compare Brush_Large (50 000 points). BUT (plotly+crosstalk) can brush both ways.
* (plotly+crosstalk) cannot use for aggregate values (eg. cannot ‘dim’ unselected values in a box plot), but with (plotly+shiny) can re-draw with selected points.
* Which allows for more flexible interaction or manipulation? Crosstalk uses ShareData to create an ‘environment’ while Plotly uses event_data() to capture default “identifiers” in a list. The Methods in the documentation of ShareData suggests it captures more info than event_data().

### Fostering Undergraduate Data Science (Review of Undergrad course in US)
* Project based, focus on large ds, interdisciplinary. Students given videos and code (flipped classroom). Specific learning targets and open-ended data exploration. One-to-one, hands on interaction during lectures. No pre-req assumed.
* Projects: approx 2 weeks in length, groups of 3 students.
* Start with data sets rather than “introducing a tool without motivation”. Motivation to solve a certain problem with the data set.
* Established skills in extracting, querying, wrangling large ds, laying the foundations for further work with large ds. Mentions visualisation in some parts.
* Picking up ’bad habits’ from overuse of stack exchange etc. (e.g. use of for loops that would be inefficient for large ds).

## Possible datasets 
### From Unwin book:
* Small datasets for teaching purposes (p.24)
    + Statlib at Carnegie Mellon University
        - <http://lib.stat.cmu.edu/datasets/>
    + UCI's Machine Learning repository: for studying algorithms
        - <http://archive.ics.uci.edu/ml/>
* UC Berkley dataset (p.9)
    + 3 categorical vars, add Shiny slider to display arrangements for a mosaic plot (reveal levels)
* Parallel coord plots: Use `iris` data set (p.105)
    + Brings out the clustering by the 3 species
    + Experiment with different scaling of axes, orderings, identify associations (compare with bivariate scatterplot)
    + Not possible to see the clustering if just used linked scatterplots? Or scatterplot matrix?
    + Compare to a 2D tour?
    + Shiny interaction to 'cycle' through different orderings of axes. Similarly w diff axes scaling (checkbox input)
    + Order vars on axes by amount of difference between groups (F-statistic) (see p.120)
    + Order of colouring obs important since the last group will be on top. Selected group should always be last to be plotted, so that it is above the rest.
* Changes in NZ Consumer Price Index over the years using paralle coord plots
    + See `Pcps for indices` under `Parallel coord plots`
    + Unwin p.113
* Mosaic plots for `Berkley` admissions' dataset is a common example
    + See: <http://www.theusrus.de/blog/understanding-mosaic-plots/>
    + An example of Simpson's paradox (where a conclusion appear true for the subsets but then disappears of reverses for the aggregate)
* Tour de France datasets analysed using Mondrian
    + Interesting short clip (10mins) of how interactive graphics (esp showcasing parallel coord plots) can be used to identify patterns in context. Good commentary (by Unwin, using data and software from Theus) <http://www.theusrus.de/blog/the-tour-is-over-long-live-the-tour/>
    + Showcases the applications of changing scale on axes of parallel coord plots.
        - Aligning times at each stage by the median time allows for comparison with the main bunch of riders, the peloton.
        - Comparing w the winner's times identifies which stages other riders gained on him.
        - In `ggparcoord` the arg `scale="center"` allows for scaling of each var's axes individually (eg. based on each var's median), so would need to manually center the data first (subtract the median time from the values), then plot (leaving `scale="globalminmax"`). (See p.115 and 116 for more info on scaling) 
    + Links to download and tutorial for Mondrian software
        - <http://www.theusrus.de/Mondrian/>

## Reading list
* Wickham, Hadley, Michael Lawrence, Dianne Cook, Andreas Buja, Heike Hofmann, and Deborah F Swayne. 2010. “The Plumbing of Interactive Graphics.” Computational Statistics, April, 1–7.

* Anthony Unwin’s Graphical Data Analysis with R (CRC Press 2015)

* GGobiMeetsR (2001)
<https://www.r-project.org/conferences/DSC-2001/Proceedings/TempleLangSwayne.pdf>
    + Code may be outdated but some good ideas

* IntroGGobi
<http://www.ggobi.org/rggobi/introduction.pdf>
    + Not sure about how up-to-date this is but seems to be a general intro (directly from the rggobi site)

* ExtendingGGobi (2008)
<https://link-springer-com.ezproxy.auckland.ac.nz/article/10.1007/s00180-008-0115-y>
    + Most recent publication (I have found so far) on rggobi

### Interactive and Dynamic Graphics for Data Analysis [^1]
* Website for book: <http://www.ggobi.org/book/index.html>
    + Code used in Cook and Swayne book and can get datasets from here

* Other courses
    + See Dropbox: Using_Interactive_Graphics_to_Teach_Multivariate_D.pdf

### Carson Sievert's paper (not yet in print)
* For code: <https://pedestrians.cpsievert.me/>
* Highlights visualisation of the model in the data space as a key use of visualisation.

* Techniques that he achieved that can be investigated further:
    + Brushing of nodes on dendrogram to select all observations under that node.
    + Smoothness of tour animation (due to data set size or otherwise?)
    + Presentation of variable coefficents for tours (subplot with plot of tour)
    + Linked brushing of parallel coordinate plots. What if brush on a shared node? (use linked tour plot instead to highlight)
    + Linked brushing of several plots using `crosstalk`.

* Interesting use of tours with time series.
    + Components of the timeseries used as the variables in the tour (eg. linearity, seasonal trend,...)
    + Similar usage as `animate_ts()` in `tourr` package?
    
* Refers to 'tasks' of interactive graphic techniques outlied in "Interactive High-Dimensional Data Visualisation" by Cook, Buja and Swayne (1996).
    + What is "Gestalt"??
    
* Sievert highlights in addtion to using graphical techniques for EDA and model diagnosis and interpretation (as suggested already by Cook and Swayne), they are also useful for "presenting results to a wider audience". The latter has been the focus of recent developments in interactive web graphics. He identifies the "lack of tools for iteration in a larger statistical computing enviroment" as a key hinderance for using web based tools for exploring data visually.

* Multiple views of one panel.
    + Requires a lot of explanation for use? Good to scaffold explanation of part of the panel first then layer on the rest.
    + Views very tailored to each specific contextual problem? Or are there common themes? ie. Use of data maps, pcp, linked brushing.
    + How does this approach compare with the law of small multiples?

* Found graphical evidence to support domain knowledge.
    + Melbourne pedestrian traffic at NYE
* Found graphical evidence to make a claim about what happened in the context.
    + Zika virus cases in Columbia being switched from confirmed to suspected.
    
* Sievert also used the `tourr` package. Some differences in approach:
    + He used `rescale()` to standardise the data values rather than the `sphere` argument. 
    + He used `new_tour()` rather than `save_history()` hence did not need to interpolate from basis to basis (this is initiated within `new_tour()`)
    
### Modern Applied Statstics with S-plus [^2]


### Visualizing Statistical Models: Removing the Blindfold [^3]
* Distinction between visualising models in the data space (m-in-ds) and the data in the model space, which is more common. 
* Advocates for more visuals for m-in-ds.

## References
(Cook & Swayne, 2007)
Cook and Swayne (2007)
Unwin (2015)
blindfold
Wickham, Cook and Hofmann (2015)
Wickham et al. (2015)
tourr package
(Wickham, Cook, Hofmann & Buja, 2011)
Wickham et al. (2011)
MASS book
Venables and Ripley (2002)
[^1]: Cook and Swayne (2007) R and GGobi book
[^2]: Venables and Ripley (2002) MASS book
[^3]: Wickham, Cook, Hofmann (2015) Remove blindfold paper
[^4]: Wickham, Cook, Hofmann, Buja (2011) tourr package paper